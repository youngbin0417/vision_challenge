{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bvb09\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "#  ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm # ë¡œì»¬ì—ì„œëŠ” tqdm.notebook ëŒ€ì‹  ì¼ë°˜ tqdm ì‚¬ìš©\n",
    "from tqdm.contrib.concurrent import thread_map\n",
    "import joblib\n",
    "import random\n",
    "\n",
    "# skimage\n",
    "from skimage.exposure import rescale_intensity, equalize_hist\n",
    "from skimage.filters import gaussian\n",
    "from skimage.restoration import denoise_bilateral\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage.feature import local_binary_pattern, hog, graycomatrix, graycoprops\n",
    "from skimage.transform import resize\n",
    "from scipy import ndimage\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder,normalize\n",
    "from sklearn.metrics import pairwise_distances, silhouette_score, confusion_matrix\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "# joblib (ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•´)\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# faiss (KNN ê°€ì†í™”ë¥¼ ìœ„í•´)\n",
    "import faiss\n",
    "\n",
    "# ë°ì´í„° ê´€ë ¨ \n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#DATASET_BASE_PATH = \"C:/Users/bvb09/.cache/kagglehub/datasets/mikhailma/test-dataset/versions/1/Google_Recaptcha_V2_Images_Dataset\"\n",
    "\n",
    "print(\"âœ” ëª¨ë“  ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸ ì™„ë£Œ!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "#  ë°ì´í„° ë¡œë“œ í•¨ìˆ˜\n",
    "# ==============================================================================\n",
    "\n",
    "# ì´ë¯¸ì§€ ë¡œë“œ í•¨ìˆ˜\n",
    "def load_images_from_folder(base_path):\n",
    "    \"\"\"\n",
    "    ì£¼ì–´ì§„ base_path ë‚´ì˜ ì„œë¸Œí´ë”(ë¼ë²¨)ì—ì„œ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•˜ê³ ,\n",
    "    ì´ë¯¸ì§€ ë°ì´í„°, ë¼ë²¨, ê·¸ë¦¬ê³  ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œë¥¼ í¬í•¨í•˜ëŠ” DataFrameì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "    (ì˜ˆ: base_path/label_name/image.jpg êµ¬ì¡°ë¥¼ ê°€ì •)\n",
    "    \"\"\"\n",
    "    images = []\n",
    "    labels = []\n",
    "    image_paths = [] # ì´ë¯¸ì§€ ê²½ë¡œë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸ ì¶”ê°€\n",
    "\n",
    "    if not os.path.exists(base_path):\n",
    "        raise FileNotFoundError(f\"ì§€ì •ëœ í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {base_path}\\n\"\n",
    "                                f\"ê²½ë¡œë¥¼ ì˜¬ë°”ë¥´ê²Œ ì„¤ì •í–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\")\n",
    "\n",
    "    print(f\"â³ Loading images from: {base_path}\")\n",
    "    # base_path ë°”ë¡œ ì•„ë˜ì˜ ëª¨ë“  í´ë”(ë¼ë²¨)ë¥¼ ìˆœíšŒí•©ë‹ˆë‹¤.\n",
    "    for label_name in tqdm(os.listdir(base_path), desc=\"í´ë” ë¡œë“œ ì¤‘\"):\n",
    "        label_path = os.path.join(base_path, label_name)\n",
    "        \n",
    "        # ì´ê²ƒì´ ì‹¤ì œ ë¼ë²¨ í´ë”ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n",
    "        if os.path.isdir(label_path):\n",
    "            for img_name in os.listdir(label_path):\n",
    "                img_path = os.path.join(label_path, img_name)\n",
    "                # ì´ë¯¸ì§€ íŒŒì¼ë§Œ ì²˜ë¦¬í•˜ë„ë¡ í™•ì¥ì í•„í„°ë§\n",
    "                if img_name.lower().endswith(('.png', '.jpg', '.jpeg', '.gif', '.bmp')):\n",
    "                    try:\n",
    "                        img = cv2.imread(img_path)\n",
    "                        if img is not None:\n",
    "                            images.append(img)\n",
    "                            labels.append(label_name)\n",
    "                            image_paths.append(img_path) # ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ ì €ì¥\n",
    "                        else:\n",
    "                            print(f\"ê²½ê³ : {img_path} ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ë¡œë“œ ì‹¤íŒ¨)\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"ê²½ê³ : {img_path} ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ - {e}\")\n",
    "                # else: (ì´ë¯¸ì§€ í™•ì¥ìê°€ ì•„ë‹Œ íŒŒì¼ì€ ë¬´ì‹œ)\n",
    "        # else: (base_path ë°”ë¡œ ì•„ë˜ì— íŒŒì¼ì´ ìˆëŠ” ê²½ìš°ëŠ” ë¬´ì‹œ, ë¼ë²¨ í´ë” êµ¬ì¡°ë¥¼ ê°€ì •)\n",
    "\n",
    "    df = pd.DataFrame({'image_data': images, 'label': labels, 'image_path': image_paths})\n",
    "    print(f\"âœ” ì´ {len(df)}ê°œì˜ ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ.\")\n",
    "    return df\n",
    "\n",
    "def visualize_features(X_feats, y_labels, method='pca'):\n",
    "    if method == 'pca':\n",
    "        reducer = PCA(n_components=2)\n",
    "    else:\n",
    "        from sklearn.manifold import TSNE\n",
    "        reducer = TSNE(n_components=2, random_state=42)\n",
    "\n",
    "    X_reduced = reducer.fit_transform(X_feats)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    scatter = plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=y_labels, cmap='tab20', s=10, alpha=0.7)\n",
    "    plt.title(f'Feature Distribution via {method.upper()}')\n",
    "    plt.colorbar(scatter, ticks=range(len(set(y_labels))))\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge(img_bgr):\n",
    "    # 1) ê°•ì œ ë¦¬ì‚¬ì´ì¦ˆ\n",
    "    img_bgr = cv2.resize(img_bgr, (120, 120), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # 2) CLAHE â†’ Gray â†’ Blur â†’ Denoise â†’ Canny\n",
    "    lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(2.0, (8,8))\n",
    "    l = clahe.apply(l)\n",
    "    img_eq = cv2.cvtColor(cv2.merge((l,a,b)), cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    gray = cv2.cvtColor(img_eq, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "    denoised = cv2.fastNlMeansDenoising(blurred, h=10, templateWindowSize=7, searchWindowSize=21)\n",
    "    edges = cv2.Canny(denoised, 100, 230)   \n",
    "\n",
    "    return edges\n",
    "\n",
    "# 1) ê³µí†µ: BGR â†’ LAB â†’ CLAHE(L) â†’ BGR (í•„ìš” ì‹œ)\n",
    "def apply_clahe(img_bgr):\n",
    "    lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    l = cv2.createCLAHE(2.0, (8,8)).apply(l)\n",
    "    return cv2.cvtColor(cv2.merge((l,a,b)), cv2.COLOR_LAB2BGR)\n",
    "\n",
    "# 3) Unsharp mask (SIFT ì „ìš©)\n",
    "def unsharp(img_gray):\n",
    "    blurred = cv2.GaussianBlur(img_gray, (3,3), 0)\n",
    "    return cv2.addWeighted(img_gray, 1.5, blurred, -0.5, 0)\n",
    "\n",
    "# 4) Mild Gaussian blur (LBP/GLCM/Laws)\n",
    "def mild_blur(img_gray):\n",
    "    return cv2.GaussianBlur(img_gray, (3,3), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray(img):\n",
    "    image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkcol(img_bgr):\n",
    "    #image = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    #image=cv2.GaussianBlur(image, ksize=(3,3), sigmaX=0)\n",
    "    #image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    #image = cv2.cvtColor(img_bgr, cv2.COLOR_GRAY2BGR)\n",
    "    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0, 1, 2], None, (8,8,8), [0,180, 0,256, 0,256])\n",
    "    hist = cv2.normalize(hist, hist).flatten()\n",
    "    h, s, v = cv2.split(hsv)\n",
    "    rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    hist_rgb = cv2.calcHist([rgb], [0, 1, 2], None, (8,8,8), [0,256, 0,256, 0,256])\n",
    "    hist_rgb = cv2.normalize(hist_rgb, hist_rgb).flatten()\n",
    "    hist_bgr = cv2.calcHist([img_bgr], [0, 1, 2], None, (8,8,8), [0,256, 0,256, 0,256])\n",
    "    hist_bgr = cv2.normalize(hist_bgr, hist_bgr).flatten()\n",
    "    #plt.imshow(v)\n",
    "    #plt.title(\"Color\")\n",
    "    #plt.axis('off')\n",
    "    #plt.show()\n",
    "     # âœ… 2D ì‹œê°í™”\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(hist, color='blue')\n",
    "    plt.title(\"Flattened HSV Histogram\")\n",
    "    plt.xlabel(\"Bin Index\")\n",
    "    plt.ylabel(\"Normalized Value\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return hsv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” íŠ¹ì§• ì¶”ì¶œ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "#  í”¼ì³ ì¶”ì¶œ í•¨ìˆ˜\n",
    "# ==================================================================:============\n",
    "\n",
    "def extract_color_histogram_features(image):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0,1,2], None, (8,8,8), [0,180,0,256,0,256])\n",
    "    return cv2.normalize(hist, hist).flatten()\n",
    "\n",
    "def extract_sift_pca_mean(img_bgr, pca_model=None, n_components=32):\n",
    "    img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(img_gray, None)\n",
    "\n",
    "    if descriptors is None or len(descriptors) == 0:\n",
    "        return np.zeros(n_components if pca_model else 128, dtype=np.float32)\n",
    "\n",
    "    if pca_model is None:\n",
    "        pca_model = PCA(n_components=n_components)\n",
    "        descriptors_pca = pca_model.fit_transform(descriptors)\n",
    "    else:\n",
    "        descriptors_pca = pca_model.transform(descriptors)\n",
    "\n",
    "    mean_vector = np.mean(descriptors_pca, axis=0)\n",
    "    return mean_vector.astype(np.float32)\n",
    "\n",
    "def extract_glcm_features(image):\n",
    "    if image is None:\n",
    "        num_props = 6\n",
    "        num_distances = 3\n",
    "        num_angles = 4\n",
    "        return np.zeros(num_props * num_distances * num_angles)\n",
    "        \n",
    "    img_glcm = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    img_glcm = mild_blur(img_glcm)\n",
    "    img_glcm = apply_clahe(cv2.cvtColor(img_glcm, cv2.COLOR_GRAY2BGR))\n",
    "    gray_image = cv2.cvtColor(img_glcm, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    distances = [1, 2, 3]\n",
    "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "    \n",
    "    try:\n",
    "        glcm = graycomatrix(gray_image, distances=distances, angles=angles, symmetric=True, normed=True)\n",
    "        \n",
    "        props_to_extract = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation', 'ASM']\n",
    "        glcm_features = []\n",
    "        for prop in props_to_extract:\n",
    "            glcm_features.append(graycoprops(glcm, prop).ravel())\n",
    "            \n",
    "        return np.concatenate(glcm_features)\n",
    "    except Exception as e:\n",
    "        print(f\"GLCM ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        num_props = 6\n",
    "        num_distances = len(distances) \n",
    "        num_angles = len(angles)   \n",
    "        return np.zeros(num_props * num_distances * num_angles)\n",
    "\n",
    "def extract_hog_features(image, orientations=9, pixels_per_cell=(16, 16), cells_per_block=(2, 2)):\n",
    "    img = cv2.resize(image, (120, 120), interpolation=cv2.INTER_AREA)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    features = hog(gray,\n",
    "                   orientations=orientations,\n",
    "                   pixels_per_cell=pixels_per_cell,\n",
    "                   cells_per_block=cells_per_block,\n",
    "                   block_norm='L2-Hys',\n",
    "                   visualize=False,\n",
    "                   transform_sqrt=True,\n",
    "                   feature_vector=True)\n",
    "    return features.astype(np.float32)\n",
    "\n",
    "def extract_sift_descriptors_from_array(image):\n",
    "    img = apply_clahe(image)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_image=unsharp(img)\n",
    "\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp, des = sift.detectAndCompute(gray_image, None)\n",
    "\n",
    "    return des\n",
    "\n",
    "def extract_lbp_features_from_array(image, P=8, R=1, method='uniform'):\n",
    "    image=apply_clahe(image)\n",
    "    image=mild_blur(image)\n",
    "    gray_image=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    lbp_image = local_binary_pattern(gray_image, P, R, method=method)\n",
    "\n",
    "    max_bins = P * (P - 1) + 3 if method == 'default' else P + 2\n",
    "    hist, _ = np.histogram(lbp_image.ravel(), bins=max_bins, range=(0, max_bins), density=True)\n",
    "    return hist\n",
    "\n",
    "\n",
    "# Laws' Texture Energy - ê¸°ì¡´ê³¼ ë™ì¼\n",
    "def extract_laws_energy_features(image, window_size=15):\n",
    "    image_gray=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image_gray=mild_blur(image_gray)\n",
    "\n",
    "    L5 = np.array([1, 4, 6, 4, 1], dtype=np.float32)\n",
    "    E5 = np.array([-1, -2, 0, 2, 1], dtype=np.float32)\n",
    "    S5 = np.array([-1, 0, 2, 0, -1], dtype=np.float32)\n",
    "    W5 = np.array([-1, 2, 0, -2, 1], dtype=np.float32)\n",
    "    R5 = np.array([1, -4, 6, -4, 1], dtype=np.float32)\n",
    "    kernels = [L5, E5, S5, W5, R5]\n",
    "\n",
    "    energy_features = []\n",
    "    if image_gray.dtype == np.uint8:\n",
    "        image_gray = image_gray.astype(np.float32)\n",
    "\n",
    "    for k1 in kernels:\n",
    "        for k2 in kernels:\n",
    "            kernel = np.outer(k1, k2)\n",
    "            filtered = ndimage.convolve(image_gray, kernel, mode='reflect')\n",
    "            energy = np.abs(filtered)\n",
    "            summed = cv2.boxFilter(energy, ddepth=-1, ksize=(window_size, window_size), normalize=False)\n",
    "            energy_features.append(summed.mean())\n",
    "\n",
    "    return np.array(energy_features, dtype=np.float32)\n",
    "\n",
    "\n",
    "def learn_bovw_vocabulary(all_sift_descriptors, num_clusters=200):\n",
    "    filtered = [des for des in all_sift_descriptors if des is not None and len(des) > 0]\n",
    "    feature_dims = {des.shape[1] for des in filtered}\n",
    "    if len(feature_dims) > 1:\n",
    "        raise ValueError(f\"âŒ BoVW í•™ìŠµìš© SIFT ë””ìŠ¤í¬ë¦½í„°ë“¤ì˜ ì°¨ì›ì´ ì¼ì¹˜í•˜ì§€ ì•ŠìŒ: {feature_dims}\")\n",
    "\n",
    "    concatenated_descriptors = np.vstack(filtered)\n",
    "    \n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    flags = cv2.KMEANS_RANDOM_CENTERS\n",
    "    _, _, centers = cv2.kmeans(\n",
    "        concatenated_descriptors.astype(np.float32),\n",
    "        num_clusters, None, criteria, 10, flags\n",
    "    )\n",
    "    return centers\n",
    "\n",
    "def create_bovw_histogram(sift_descriptors, vocabulary):\n",
    "    num_clusters = vocabulary.shape[0]\n",
    "    if sift_descriptors is None or len(sift_descriptors) == 0:\n",
    "        return np.zeros(num_clusters, dtype=np.float32)\n",
    "\n",
    "    try:\n",
    "        distances = np.linalg.norm(\n",
    "            vocabulary[None, :, :] - sift_descriptors[:, None, :], axis=2\n",
    "        )\n",
    "        closest_clusters = np.argmin(distances, axis=1)\n",
    "        histogram = np.bincount(closest_clusters, minlength=num_clusters).astype(np.float32)\n",
    "        histogram = cv2.normalize(histogram, None, norm_type=cv2.NORM_L2).flatten()\n",
    "        return histogram\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ BoVW íˆìŠ¤í† ê·¸ë¨ ìƒì„± ì˜¤ë¥˜: {e}\")\n",
    "        return np.zeros(num_clusters, dtype=np.float32)\n",
    "\n",
    "\n",
    "def parallel_create_bovw_histograms(descriptor_list, vocabulary, n_jobs=6):\n",
    "    histograms = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(create_bovw_histogram)(desc, vocabulary) for desc in descriptor_list\n",
    "    )\n",
    "    return np.array(histograms, dtype=np.float32)\n",
    "\n",
    "print(\"âœ” íŠ¹ì§• ì¶”ì¶œ í•¨ìˆ˜ ì •ì˜ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "#  ë¶„ë¥˜ ëª¨ë¸ ë° í•™ìŠµ/í‰ê°€ í•¨ìˆ˜\n",
    "# ==============================================================================\n",
    "# ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê¸°ë°˜ Faiss KNN í•™ìŠµ (ìˆ˜ì •ë¨)\n",
    "\n",
    "def combine_features(*feature_arrays):\n",
    "    \"\"\"ì£¼ì–´ì§„ íŠ¹ì§• ë°°ì—´ë“¤ì„ ê°€ë¡œë¡œ ê²°í•©í•©ë‹ˆë‹¤.\"\"\"\n",
    "    return np.hstack(feature_arrays)\n",
    "\n",
    "def train_faiss_knn_euclidean(X_train, y_train, n_neighbors=3):\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    D = X_train.shape[1]\n",
    "\n",
    "    index = faiss.IndexFlatL2(D)\n",
    "    index.add(X_train)\n",
    "\n",
    "    return index, y_train, n_neighbors\n",
    "\n",
    "# ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê¸°ë°˜ Faiss KNN ì˜ˆì¸¡ (ìˆ˜ì •ë¨)\n",
    "def predict_faiss_knn_euclidean(index, y_train_labels, n_neighbors, X_test):\n",
    "    X_test = X_test.astype(np.float32)\n",
    "\n",
    "    distances, indices = index.search(X_test, n_neighbors)\n",
    "\n",
    "    y_pred = []\n",
    "    for i in range(len(X_test)):\n",
    "        neighbor_labels = y_train_labels[indices[i]]\n",
    "        unique_labels, counts = np.unique(neighbor_labels, return_counts=True)\n",
    "        predicted_label = unique_labels[np.argmax(counts)]\n",
    "        y_pred.append(predicted_label)\n",
    "    return np.array(y_pred)\n",
    "\n",
    "# ê¸°ì¡´ predict_faiss_knn_euclidean í•¨ìˆ˜ë¥¼ ìˆ˜ì •í•˜ê±°ë‚˜, ì•„ë˜ í•¨ìˆ˜ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.\n",
    "# ì´ í•¨ìˆ˜ëŠ” kê°œì˜ ê°€ì¥ ê°€ê¹Œìš´ ì´ì›ƒì˜ ë¼ë²¨ì„ ë°˜í™˜í•©ë‹ˆë‹¤.\n",
    "def predict_faiss_knn_topk(faiss_index, train_labels_encoded, query_features, k=10):\n",
    "    if faiss_index is None:\n",
    "        raise ValueError(\"Faiss ì¸ë±ìŠ¤ê°€ í•™ìŠµë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.\")\n",
    "    if query_features.shape[0] == 0:\n",
    "        return np.array([]), np.array([]), np.array([])\n",
    "\n",
    "    D, I = faiss_index.search(query_features, k)\n",
    "    predicted_neighbor_labels = train_labels_encoded[I]\n",
    "\n",
    "    return D, I, predicted_neighbor_labels\n",
    "\n",
    "# ì°¸ê³ : ê¸°ì¡´ predict_faiss_knn_euclidean í•¨ìˆ˜ëŠ” ë‹¨ìˆœíˆ k=1ë¡œ ì„¤ì •í•˜ê³  ì²« ë²ˆì§¸ ë¼ë²¨ì„ ë°˜í™˜í•˜ëŠ” ì‹ìœ¼ë¡œ ë™ì‘í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
    "# ë§Œì•½ ê¸°ì¡´ predict_faiss_knn_euclidean í•¨ìˆ˜ê°€ kë¥¼ ì¸ìë¡œ ë°›ëŠ”ë‹¤ë©´, ê·¸ í•¨ìˆ˜ë¥¼ í™œìš©í•´ë„ ì¢‹ìŠµë‹ˆë‹¤.\n",
    "# ì—¬ê¸°ì„œëŠ” Top-k ê²°ê³¼ë¥¼ ì§ì ‘ ë‹¤ë£° ìˆ˜ ìˆë„ë¡ predict_faiss_knn_topkë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
    "\n",
    "# Task2 Accuracy (Top-K Same-Class)ë¥¼ ê³„ì‚°í•˜ëŠ” í•¨ìˆ˜\n",
    "def task2_score(y_true, topk_preds, topk=10):\n",
    "    match_counts = []\n",
    "    for true_label, pred_list_np in zip(y_true, topk_preds):\n",
    "        # NumPy ë°°ì—´ì„ Python ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ì—¬ .count() ë©”ì„œë“œ ì‚¬ìš©\n",
    "        pred_list = pred_list_np.tolist()\n",
    "        # topk_predsì˜ ê° ìš”ì†Œ(pred_list)ëŠ” ì‹¤ì œ ë¼ë²¨ì´ í¬í•¨ëœ íšŸìˆ˜ / topk\n",
    "        # ì˜ˆë¥¼ ë“¤ì–´, topk=10ì¼ ë•Œ, 'car' ë¼ë²¨ì´ 3ë²ˆ ë“±ì¥í•˜ë©´ 3/10 = 0.3\n",
    "        match_counts.append(pred_list.count(true_label) / topk)\n",
    "    return np.mean(match_counts)\n",
    "\n",
    "def test(model_tuple, X_test, y_test, average='weighted', topk=10):\n",
    "    faiss_index, y_train_labels, n_neighbors = model_tuple\n",
    "    \n",
    "    print(f\" Â â–¶ KNN ì˜ˆì¸¡ ì¤‘ (Faiss ì‚¬ìš©, k={n_neighbors})...\")\n",
    "    \n",
    "    # Top-1 ì˜ˆì¸¡ (ê¸°ì¡´)\n",
    "    y_pred = predict_faiss_knn_euclidean(faiss_index, y_train_labels, n_neighbors, X_test)\n",
    "\n",
    "    # Top-k ì˜ˆì¸¡ì„ ìœ„í•´ predict_faiss_knn_topk ì‚¬ìš©\n",
    "    # D, IëŠ” í•„ìš” ì—†ìœ¼ë¯€ë¡œ _ ì²˜ë¦¬\n",
    "    _, _, topk_predicted_labels_encoded = predict_faiss_knn_topk(faiss_index, y_train_labels, X_test, k=topk)\n",
    "\n",
    "    print(\" Â âœ” ì˜ˆì¸¡ ì™„ë£Œ.\")\n",
    "    \n",
    "    # Top-1 Accuracy\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average=average, zero_division=0)\n",
    "    rec  = recall_score(y_test, y_pred, average=average, zero_division=0)\n",
    "\n",
    "    # Top-k Accuracy ê³„ì‚° (ê¸°ì¡´ ë°©ì‹)\n",
    "    topk_correct_count = 0\n",
    "    for i in range(len(y_test)):\n",
    "        # y_test[i] (ì‹¤ì œ ë¼ë²¨)ì´ ìƒìœ„ kê°œ ì˜ˆì¸¡ ë¼ë²¨ ì¤‘ í•˜ë‚˜ë¼ë„ ìˆëŠ”ì§€ í™•ì¸\n",
    "        if y_test[i] in topk_predicted_labels_encoded[i]:\n",
    "            topk_correct_count += 1\n",
    "    topk_acc = topk_correct_count / len(y_test)\n",
    "\n",
    "    # --- ì—¬ê¸°ì— Task2 Accuracy (Top-10 Same-Class) ê³„ì‚° ë° ì¶œë ¥ ì¶”ê°€ ---\n",
    "    # task2_score í•¨ìˆ˜ê°€ ì •ì˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n",
    "    # ë§Œì•½ task2_score í•¨ìˆ˜ê°€ ì•„ì§ ì •ì˜ë˜ì§€ ì•Šì•˜ë‹¤ë©´, ì´ì „ì— ì œê³µëœ ì½”ë“œë¥¼ ì¶”ê°€í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "    # (ì˜ˆ: def task2_score(y_true, topk_preds, topk=10): ... )\n",
    "    task2_acc = task2_score(y_test, topk_predicted_labels_encoded, topk=topk)\n",
    "    # ------------------------------------------------------------------\n",
    "\n",
    "    print(f\"[Top-1 Accuracy]    {acc:.4f}\")\n",
    "    print(f\"[Task2 Accuracy (Top-{topk} Same-Class)] {task2_acc:.4f}\") # ì´ ì¤„ì„ ì¶”ê°€\n",
    "    print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, title='Confusion Matrix', normalize=False):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\".2f\" if normalize else \"d\", cmap=\"Blues\",\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(img):\n",
    "    choice = random.choice(['flip', 'rotate', 'brightness', 'blur', 'noise'])\n",
    "    if choice == 'flip':\n",
    "        return cv2.flip(img, 1)\n",
    "    elif choice == 'rotate':\n",
    "        angle = random.uniform(-15, 15)\n",
    "        h, w = img.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w // 2, h // 2), angle, 1.0)\n",
    "        return cv2.warpAffine(img, M, (w, h), borderMode=cv2.BORDER_REFLECT)\n",
    "    elif choice == 'brightness':\n",
    "        factor = random.uniform(0.7, 1.3)\n",
    "        return np.clip(img.astype(np.float32) * factor, 0, 255).astype(np.uint8)\n",
    "    elif choice == 'blur':\n",
    "        return cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    elif choice == 'noise':\n",
    "        noise = np.random.normal(0, 10, img.shape).astype(np.uint8)\n",
    "        return cv2.add(img, noise)\n",
    "    return img\n",
    "\n",
    "def augment_to_balance_min(df, target_min_per_class=500, seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    augmented_rows = []\n",
    "\n",
    "    for label, group in df.groupby('label'):\n",
    "        n_current = len(group)\n",
    "        n_needed = target_min_per_class - n_current\n",
    "\n",
    "        if n_needed <= 0:\n",
    "            print(f\"âœ… {label}: {n_current}ê°œ â†’ ê·¸ëŒ€ë¡œ ìœ ì§€ (ì¦ê°• ì—†ìŒ)\")\n",
    "            augmented_rows.append(group)\n",
    "        else:\n",
    "            print(f\"â• {label}: {n_current}ê°œ â†’ {target_min_per_class}ê°œë¡œ ì¦ê°• ì¤‘ ({n_needed}ê°œ ìƒì„±)\")\n",
    "            samples_to_augment = group.sample(n=n_needed, replace=True, random_state=seed)\n",
    "\n",
    "            new_rows = []\n",
    "            for _, row in samples_to_augment.iterrows():\n",
    "                new_img = augment_image(row['image_data'])\n",
    "                # ì¦ê°•ëœ ì´ë¯¸ì§€ì—ëŠ” image_pathë¥¼ ìƒˆë¡œ í• ë‹¹í•  í•„ìš”ê°€ ì—†ìœ¼ë¯€ë¡œ image_dataë§Œ ì¶”ê°€\n",
    "                new_rows.append({\n",
    "                    'label': row['label'],\n",
    "                    'image_data': new_img\n",
    "                })\n",
    "            augmented_rows.append(group)\n",
    "            augmented_rows.append(pd.DataFrame(new_rows))\n",
    "\n",
    "    balanced_df = pd.concat(augmented_rows).reset_index(drop=True)\n",
    "    return balanced_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ Loading images from: C:/Users/bvb09/recaptcha-dataset\\images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "í´ë” ë¡œë“œ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10/10 [00:38<00:00,  3.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” ì´ 13408ê°œì˜ ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ.\n",
      "âœ” ì´ 13408ê°œì˜ ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ.\n",
      "âœ” ë¼ë²¨ ì¸ì½”ë”© ì™„ë£Œ. í´ë˜ìŠ¤: ['Bicycle' 'Bridge' 'Bus' 'Car' 'Chimney' 'Crosswalk' 'Hydrant'\n",
      " 'Motorcycle' 'Palm' 'Traffic Light']\n",
      "âœ… Bicycle: 1299ê°œ â†’ ê·¸ëŒ€ë¡œ ìœ ì§€ (ì¦ê°• ì—†ìŒ)\n",
      "âœ… Bridge: 1278ê°œ â†’ ê·¸ëŒ€ë¡œ ìœ ì§€ (ì¦ê°• ì—†ìŒ)\n",
      "âœ… Bus: 1500ê°œ â†’ ê·¸ëŒ€ë¡œ ìœ ì§€ (ì¦ê°• ì—†ìŒ)\n",
      "âœ… Car: 1500ê°œ â†’ ê·¸ëŒ€ë¡œ ìœ ì§€ (ì¦ê°• ì—†ìŒ)\n",
      "â• Chimney: 431ê°œ â†’ 500ê°œë¡œ ì¦ê°• ì¤‘ (69ê°œ ìƒì„±)\n",
      "âœ… Crosswalk: 1260ê°œ â†’ ê·¸ëŒ€ë¡œ ìœ ì§€ (ì¦ê°• ì—†ìŒ)\n",
      "âœ… Hydrant: 1032ê°œ â†’ ê·¸ëŒ€ë¡œ ìœ ì§€ (ì¦ê°• ì—†ìŒ)\n",
      "âœ… Motorcycle: 679ê°œ â†’ ê·¸ëŒ€ë¡œ ìœ ì§€ (ì¦ê°• ì—†ìŒ)\n",
      "âœ… Palm: 932ê°œ â†’ ê·¸ëŒ€ë¡œ ìœ ì§€ (ì¦ê°• ì—†ìŒ)\n",
      "âœ… Traffic Light: 905ê°œ â†’ ê·¸ëŒ€ë¡œ ìœ ì§€ (ì¦ê°• ì—†ìŒ)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\bvb09\\AppData\\Local\\Temp\\ipykernel_4040\\2780136523.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  images_df = images_df.groupby('label').apply(\n"
     ]
    }
   ],
   "source": [
    "DATASET_BASE_PATH = \"C:/Users/bvb09/recaptcha-dataset\" \n",
    "\n",
    "try:\n",
    "    images_df = load_images_from_folder(os.path.join(DATASET_BASE_PATH, 'images'))\n",
    "    print(f\"âœ” ì´ {len(images_df)}ê°œì˜ ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"ì˜¤ë¥˜: {e}\")\n",
    "    \n",
    "\n",
    "# 2. ë¼ë²¨ ì¸ì½”ë”©\n",
    "le = LabelEncoder()\n",
    "images_df['label_encoded'] = le.fit_transform(images_df['label'])\n",
    "print(f\"âœ” ë¼ë²¨ ì¸ì½”ë”© ì™„ë£Œ. í´ë˜ìŠ¤: {le.classes_}\")\n",
    "\n",
    "images_df = images_df.groupby('label').apply(\n",
    "    lambda g: g.sample(n=1500, random_state=42) if g.name in ['Car', 'Bus'] else g\n",
    ").reset_index(drop=True)\n",
    "\n",
    "images_df = augment_to_balance_min(images_df)\n",
    "images_df['label_encoded'] = le.fit_transform(images_df['label'])\n",
    "\n",
    "# ì „ì²´ ì´ë¯¸ì§€ ë°ì´í„°ì— ëŒ€í•´ ì „ì²˜ë¦¬ ìˆ˜í–‰\n",
    "#print(\"â³ ì „ì²´ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì¤‘...\")\n",
    "#images_df['processed_image_data'] = [preprocess_image(img) for img in tqdm(images_df['image_data'], desc=\"ì´ë¯¸ì§€ ì „ì²˜ë¦¬\")]\n",
    "#print(\"âœ” ì „ì²´ ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ì™„ë£Œ.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Color Histogram ì¶”ì¶œ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10885/10885 [00:00<00:00, 19104.68it/s]\n"
     ]
    }
   ],
   "source": [
    "features_color_all = np.array([extract_color_histogram_features(img) for img in tqdm(images_df['image_data'], desc=\"Color Histogram ì¶”ì¶œ\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LBP ì¶”ì¶œ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10885/10885 [00:19<00:00, 563.99it/s]\n"
     ]
    }
   ],
   "source": [
    "features_lbp_all = np.array([extract_lbp_features_from_array(img) for img in tqdm(images_df['image_data'], desc=\"LBP ì¶”ì¶œ\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HOG ì¶”ì¶œ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10885/10885 [00:14<00:00, 727.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - HOG ì›ë³¸ íŠ¹ì§• ì°¨ì›: (10885, 1296)\n",
      "  - HOG PCA ë³€í™˜ ì™„ë£Œ. ë³€í™˜ í›„ ì°¨ì›: (10885, 50)\n"
     ]
    }
   ],
   "source": [
    "hog_list = [\n",
    "    extract_hog_features(img)\n",
    "    for img in tqdm(images_df['image_data'], desc=\"HOG ì¶”ì¶œ\")\n",
    "]\n",
    "features_hog_all = np.vstack(hog_list)\n",
    "print(f\"  - HOG ì›ë³¸ íŠ¹ì§• ì°¨ì›: {features_hog_all.shape}\")\n",
    "pca_hog = PCA(n_components=50, random_state=42)\n",
    "features_hog_all = pca_hog.fit_transform(features_hog_all)\n",
    "print(f\"  - HOG PCA ë³€í™˜ ì™„ë£Œ. ë³€í™˜ í›„ ì°¨ì›: {features_hog_all.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features_glcm_all = np.array([extract_glcm_features(img) for img in tqdm(images_df['image_data'], desc=\"GLCM ì¶”ì¶œ\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features_laws_all = np.array([extract_laws_energy_features(img) for img in tqdm(images_df['image_data'], desc=\"Laws' Texture ì¶”ì¶œ\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_reduce_descriptors(sift_descriptors_list_all, n_components=64):\n",
    "    \"\"\"\n",
    "    ëª¨ë“  ì´ë¯¸ì§€ì˜ SIFT ë””ìŠ¤í¬ë¦½í„°ì— ëŒ€í•´ PCAë¥¼ ì ìš©í•´ ì°¨ì› ì¶•ì†Œ.\n",
    "    PCAëŠ” ì „ì²´ ë””ìŠ¤í¬ë¦½í„°ì—ì„œ 1íšŒ í•™ìŠµí•œ ë’¤, ê° ë””ìŠ¤í¬ë¦½í„°ì— transformë§Œ ì ìš©.\n",
    "    \"\"\"\n",
    "    # ìœ íš¨í•œ ë””ìŠ¤í¬ë¦½í„°ë§Œ ì¶”ì¶œ (None ì œê±°, ìµœì†Œ ì°¨ì› ì´ìƒ)\n",
    "    valid_descriptors = [d for d in sift_descriptors_list_all if d is not None and len(d) >= n_components]\n",
    "    \n",
    "    if len(valid_descriptors) == 0:\n",
    "        print(\"âŒ PCA í•™ìŠµí•  ë””ìŠ¤í¬ë¦½í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŒ. ì°¨ì› ì¶•ì†Œë¥¼ ìƒëµí•©ë‹ˆë‹¤.\")\n",
    "        return sift_descriptors_list_all\n",
    "\n",
    "    # ì „ì²´ ë””ìŠ¤í¬ë¦½í„° ê²°í•©\n",
    "    all_descriptors = np.vstack(valid_descriptors)\n",
    "\n",
    "    # PCA í•™ìŠµ\n",
    "    print(f\"ğŸ” PCA í•™ìŠµ ì¤‘... (ì…ë ¥ ì°¨ì›: {all_descriptors.shape[1]} â†’ {n_components})\")\n",
    "    pca_sift = PCA(n_components=n_components, random_state=42)\n",
    "    pca_sift.fit(all_descriptors)\n",
    "\n",
    "    # ë³‘ë ¬ ë³€í™˜ í•¨ìˆ˜\n",
    "    def transform_if_valid(desc):\n",
    "        if desc is None or len(desc) < n_components:\n",
    "            return desc\n",
    "        return pca_sift.transform(desc)\n",
    "\n",
    "    # ë³‘ë ¬ ì ìš©\n",
    "    print(\"âš™ PCA ë³€í™˜ ë³‘ë ¬ ì ìš© ì¤‘...\")\n",
    "    reduced_descriptors = Parallel(n_jobs=6)(\n",
    "        delayed(transform_if_valid)(desc) for desc in sift_descriptors_list_all\n",
    "    )\n",
    "    \n",
    "    print(\"âœ… PCA ì¶•ì†Œ ì™„ë£Œ\")\n",
    "    return reduced_descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SIFT Descriptors ì¶”ì¶œ: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10885/10885 [01:25<00:00, 127.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š ì „ì²´ ì´ë¯¸ì§€ ìˆ˜: 10885\n",
      "ğŸ“Š PCA í•™ìŠµì— ì‚¬ìš©ëœ SIFT ë””ìŠ¤í¬ë¦½í„°ê°€ ìˆëŠ” ì´ë¯¸ì§€ ìˆ˜: 10885\n",
      "ğŸ“Š PCA í•™ìŠµì— ì‚¬ìš©ëœ ì „ì²´ SIFT ë²¡í„° ìˆ˜: 1862828\n",
      "âœ… SIFT ë””ìŠ¤í¬ë¦½í„° PCA ë³€í™˜ ì™„ë£Œ.\n"
     ]
    }
   ],
   "source": [
    "# SIFT ë””ìŠ¤í¬ë¦½í„° ì¶”ì¶œ\n",
    "sift_descriptors_list_all = [extract_sift_descriptors_from_array(img) for img in tqdm(images_df['image_data'], desc=\"SIFT Descriptors ì¶”ì¶œ\")]\n",
    "\n",
    "# ì „ì²´ ì´ë¯¸ì§€ ìˆ˜\n",
    "total_count = len(sift_descriptors_list_all)\n",
    "\n",
    "# PCA í•™ìŠµì— ì‚¬ìš©í•  ë””ìŠ¤í¬ë¦½í„°ë§Œ í•„í„°ë§ (128ì°¨ì›ì¸ ê²½ìš°ë§Œ)\n",
    "all_descriptors = [des for des in sift_descriptors_list_all if des is not None and des.shape[1] == 128]\n",
    "pca_image_count = len(all_descriptors)\n",
    "\n",
    "if len(all_descriptors) > 0: # PCA í•™ìŠµí•  ë°ì´í„°ê°€ ìˆì„ ê²½ìš°ì—ë§Œ ì§„í–‰\n",
    "    X_all_sift_for_pca = np.vstack(all_descriptors) # SIFT PCAë¥¼ ìœ„í•œ ë°ì´í„°\n",
    "    pca_sift = PCA(n_components=64, random_state=42)\n",
    "    pca_sift.fit(X_all_sift_for_pca)\n",
    "\n",
    "    print(f\"ğŸ“Š ì „ì²´ ì´ë¯¸ì§€ ìˆ˜: {total_count}\")\n",
    "    print(f\"ğŸ“Š PCA í•™ìŠµì— ì‚¬ìš©ëœ SIFT ë””ìŠ¤í¬ë¦½í„°ê°€ ìˆëŠ” ì´ë¯¸ì§€ ìˆ˜: {pca_image_count}\")\n",
    "    print(f\"ğŸ“Š PCA í•™ìŠµì— ì‚¬ìš©ëœ ì „ì²´ SIFT ë²¡í„° ìˆ˜: {X_all_sift_for_pca.shape[0]}\")\n",
    "\n",
    "    # PCA ë³€í™˜ ì ìš©\n",
    "    sift_descriptors_list_all = [\n",
    "        pca_sift.transform(des) if des is not None and des.shape[1] == 128 else None\n",
    "        for des in sift_descriptors_list_all\n",
    "    ]\n",
    "    print(\"âœ… SIFT ë””ìŠ¤í¬ë¦½í„° PCA ë³€í™˜ ì™„ë£Œ.\")\n",
    "else:\n",
    "    print(\"âš ï¸ SIFT ë””ìŠ¤í¬ë¦½í„°ê°€ ì—†ê±°ë‚˜ PCA í•™ìŠµì— ì‚¬ìš©í•  ë°ì´í„°ê°€ ì¶©ë¶„í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. SIFT PCAë¥¼ ê±´ë„ˆëœœë‹ˆë‹¤.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” ì „ì²´ BoVW Vocabulary í•™ìŠµ ì™„ë£Œ (200 clusters)\n",
      "  - BoVW Histogram ì°¨ì›: (10885, 200)\n",
      "âœ” íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ.\n",
      "âœ” í•™ìŠµ ë°ì´í„° í†µí•© íŠ¹ì§• ë²¡í„° ìƒì„± ì™„ë£Œ. Shape: (10885, 772)\n",
      "âœ” ì „ì²´ ë°ì´í„°ë¡œ Faiss KNN í•™ìŠµ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------------------\n",
    "# 1. ì „ì²´ SIFT â†’ BoVW Vocabulary í•™ìŠµ\n",
    "# ----------------------------------------\n",
    "valid_sift_descriptors_all = [d for d in sift_descriptors_list_all if d is not None and len(d) > 0]\n",
    "if valid_sift_descriptors_all:\n",
    "    bovw_vocabulary = learn_bovw_vocabulary(valid_sift_descriptors_all, num_clusters=200)\n",
    "    print(f\"âœ” ì „ì²´ BoVW Vocabulary í•™ìŠµ ì™„ë£Œ ({bovw_vocabulary.shape[0]} clusters)\")\n",
    "else:\n",
    "    print(\"âš ï¸ ìœ íš¨í•œ SIFT ë””ìŠ¤í¬ë¦½í„°ê°€ ì—†ì–´ BoVW Vocabularyë¥¼ í•™ìŠµí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    # Vocabularyê°€ ì—†ìœ¼ë©´ BoVW íˆìŠ¤í† ê·¸ë¨ ìƒì„± ì‹œ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë¯€ë¡œ, ë¹ˆ Vocabularyë¥¼ ì •ì˜í•©ë‹ˆë‹¤.\n",
    "    bovw_vocabulary = np.zeros((200, 64)) # ì˜ˆì‹œ: 200 í´ëŸ¬ìŠ¤í„°, SIFT PCA ì°¨ì› 64ë¡œ ê°€ì •\n",
    "\n",
    "\n",
    "# ----------------------------------------\n",
    "# 2. BoVW Histogram ì „ì²´ ìƒì„±\n",
    "# ----------------------------------------\n",
    "bovw_hist_all = np.array(parallel_create_bovw_histograms(sift_descriptors_list_all, bovw_vocabulary, n_jobs=-1))\n",
    "print(f\"  - BoVW Histogram ì°¨ì›: {bovw_hist_all.shape}\")\n",
    "print(\"âœ” íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ.\")\n",
    "# ----------------------------------------\n",
    "# 3. ì¡°í•©: color+lbp+sift+hog\n",
    "# ----------------------------------------\n",
    "feature_combo = ('color', 'lbp', 'sift', 'hog')\n",
    "X_features_list = [\n",
    "    features_color_all,\n",
    "    features_lbp_all,\n",
    "    features_hog_all,\n",
    "    bovw_hist_all\n",
    "]\n",
    "X_all_combined = combine_features(*X_features_list).astype(np.float32)\n",
    "y_all_encoded = images_df['label_encoded'].values\n",
    "print(f\"âœ” í•™ìŠµ ë°ì´í„° í†µí•© íŠ¹ì§• ë²¡í„° ìƒì„± ì™„ë£Œ. Shape: {X_all_combined.shape}\")\n",
    "\n",
    "# ----------------------------------------\n",
    "# 4. Faiss KNN ì „ì²´ í•™ìŠµ\n",
    "# ----------------------------------------\n",
    "faiss_index, train_labels_for_pred, _ = train_faiss_knn_euclidean(X_all_combined, y_all_encoded, n_neighbors=10)\n",
    "print(\"âœ” ì „ì²´ ë°ì´í„°ë¡œ Faiss KNN í•™ìŠµ ì™„ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì˜¤ë¥˜ ë°œìƒ: íŒŒì¼ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. [Errno 2] No such file or directory: './model_outputs1/feautres.pkl'\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "#  ì¶”ì¶œëœ í”¼ì²˜, ë¼ë²¨, í•™ìŠµëœ ëª¨ë¸ë“¤ ì €ì¥ (ìƒˆë¡œ ì¶”ê°€)\n",
    "# ==============================================================================\n",
    "\n",
    "SAVE_DIR = './model_outputs1'\n",
    "try:\n",
    "    joblib.dump(X_all_combined, './model_outputs1/feautres.pkl') # feature vector\n",
    "    joblib.dump(y_all_encoded, './model_outputs1/labels.pkl') # label\n",
    "    joblib.dump(le, './model_outputs1/label_encoder.pkl') # ë¼ë²¨ ì¸ì½”ë” ì €ì¥\n",
    "    \n",
    "    joblib.dump(pca_hog, './model_outputs1/pca_hog.pkl')\n",
    "    joblib.dump(pca_sift, './model_outputs1/pca_sift.pkl')\n",
    "    \n",
    "    np.save(\"model_outputs1/bovw_vocabulary.npy\", bovw_vocabulary)\n",
    "    faiss.write_index(faiss_index, \"model_outputs1/faiss_index.idx\")\n",
    "\n",
    "    print(f\"âœ” ëª¨ë“  í•™ìŠµ ê´€ë ¨ íŒŒì¼ì´ '{SAVE_DIR}' í´ë”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: íŒŒì¼ ì €ì¥ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "â³ Loading images from: C:/query\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "í´ë” ë¡œë“œ ì¤‘: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ” ì´ 0ê°œì˜ ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ.\n",
      "âœ” ì´ 0ê°œì˜ ì¿¼ë¦¬ ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ.\n",
      "â³ ì¿¼ë¦¬ ì´ë¯¸ì§€ ê¸°ë³¸ íŠ¹ì§• ì¶”ì¶œ ì¤‘ (Color, HOG, LBP, SIFT descriptors)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query Color Histogram ì¶”ì¶œ: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Color Histogram íŠ¹ì§• ì°¨ì›: (0,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query LBP ì¶”ì¶œ: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - LBP íŠ¹ì§• ì°¨ì›: (0,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Query HOG ì¶”ì¶œ: 0it [00:00, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "need at least one array to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 25\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# HOG ì¶”ì¶œ\u001b[39;00m\n\u001b[32m     21\u001b[39m query_hog_list = [\n\u001b[32m     22\u001b[39m     extract_hog_features(img)\n\u001b[32m     23\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m tqdm(query_df[\u001b[33m'\u001b[39m\u001b[33mimage_data\u001b[39m\u001b[33m'\u001b[39m], desc=\u001b[33m\"\u001b[39m\u001b[33mQuery HOG ì¶”ì¶œ\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     24\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m query_features_hog = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_hog_list\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  - HOG ì›ë³¸ íŠ¹ì§• ì°¨ì›: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery_features_hog.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# HOG PCA ë³€í™˜ (í•™ìŠµ ì‹œ ì‚¬ìš©í•œ pca_hog ëª¨ë¸ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bvb09\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\_core\\shape_base.py:292\u001b[39m, in \u001b[36mvstack\u001b[39m\u001b[34m(tup, dtype, casting)\u001b[39m\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    291\u001b[39m     arrs = (arrs,)\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mValueError\u001b[39m: need at least one array to concatenate"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "#  ì¿¼ë¦¬ ì´ë¯¸ì§€ ì²˜ë¦¬ ë° ì˜ˆì¸¡ (ìˆ˜ì •ëœ ì½”ë“œ)\n",
    "# ==============================================================================\n",
    "\n",
    "# 1. ì¿¼ë¦¬ ì´ë¯¸ì§€ ë¡œë“œ\n",
    "query_df = load_images_from_folder(\"C:/query/images\")\n",
    "print(f\"âœ” ì´ {len(query_df)}ê°œì˜ ì¿¼ë¦¬ ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ.\")\n",
    "\n",
    "# 2. ì¿¼ë¦¬ ì´ë¯¸ì§€ì— ëŒ€í•œ íŠ¹ì§• ì¶”ì¶œ\n",
    "print(\"â³ ì¿¼ë¦¬ ì´ë¯¸ì§€ ê¸°ë³¸ íŠ¹ì§• ì¶”ì¶œ ì¤‘ (Color, HOG, LBP, SIFT descriptors)...\")\n",
    "\n",
    "# Color Histogram ì¶”ì¶œ\n",
    "query_features_color = np.array([extract_color_histogram_features(img) for img in tqdm(query_df['image_data'], desc=\"Query Color Histogram ì¶”ì¶œ\")])\n",
    "print(f\"  - Color Histogram íŠ¹ì§• ì°¨ì›: {query_features_color.shape}\")\n",
    "\n",
    "# LBP ì¶”ì¶œ\n",
    "query_features_lbp = np.array([extract_lbp_features_from_array(img) for img in tqdm(query_df['image_data'], desc=\"Query LBP ì¶”ì¶œ\")])\n",
    "print(f\"  - LBP íŠ¹ì§• ì°¨ì›: {query_features_lbp.shape}\")\n",
    "\n",
    "# HOG ì¶”ì¶œ\n",
    "query_hog_list = [\n",
    "    extract_hog_features(img)\n",
    "    for img in tqdm(query_df['image_data'], desc=\"Query HOG ì¶”ì¶œ\")\n",
    "]\n",
    "query_features_hog = np.vstack(query_hog_list)\n",
    "print(f\"  - HOG ì›ë³¸ íŠ¹ì§• ì°¨ì›: {query_features_hog.shape}\")\n",
    "\n",
    "# HOG PCA ë³€í™˜ (í•™ìŠµ ì‹œ ì‚¬ìš©í•œ pca_hog ëª¨ë¸ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©)\n",
    "if 'pca_hog' in locals() and pca_hog is not None:\n",
    "    query_features_hog = pca_hog.transform(query_features_hog)\n",
    "    print(f\"  - HOG PCA ë³€í™˜ ì™„ë£Œ. ë³€í™˜ í›„ ì°¨ì›: {query_features_hog.shape}\")\n",
    "else:\n",
    "    print(\"  âš ï¸ pca_hog ëª¨ë¸ì´ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. HOG PCAë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
    "\n",
    "# SIFT ë””ìŠ¤í¬ë¦½í„° ì¶”ì¶œ\n",
    "query_sift_descriptors_list = [extract_sift_descriptors_from_array(img) for img in tqdm(query_df['image_data'], desc=\"Query SIFT Descriptors ì¶”ì¶œ\")]\n",
    "\n",
    "# SIFT ë””ìŠ¤í¬ë¦½í„° PCA ë³€í™˜ (í•™ìŠµ ì‹œ ì‚¬ìš©í•œ pca_sift ëª¨ë¸ì„ ê·¸ëŒ€ë¡œ ì‚¬ìš©)\n",
    "if 'pca_sift' in locals() and pca_sift is not None:\n",
    "    query_sift_descriptors_list = [\n",
    "        pca_sift.transform(des) if des is not None and des.shape[1] == 128 else None\n",
    "        for des in query_sift_descriptors_list\n",
    "    ]\n",
    "    print(f\"  - SIFT ë””ìŠ¤í¬ë¦½í„° PCA ë³€í™˜ ì™„ë£Œ.\")\n",
    "else:\n",
    "    print(\"  âš ï¸ pca_sift ëª¨ë¸ì´ ì •ì˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. SIFT PCAë¥¼ ê±´ë„ˆëœœë‹ˆë‹¤.\")\n",
    "\n",
    "\n",
    "# BoVW Histogram ìƒì„± (í•™ìŠµ ì‹œ ì‚¬ìš©í•œ bovw_vocabularyë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©)\n",
    "valid_query_sift_descriptors_list = [des for des in query_sift_descriptors_list if des is not None]\n",
    "\n",
    "if valid_query_sift_descriptors_list:\n",
    "    query_bovw_hist = np.array(parallel_create_bovw_histograms(valid_query_sift_descriptors_list, bovw_vocabulary, n_jobs=-1))\n",
    "    temp_bovw_hist_idx = 0\n",
    "    final_query_bovw_hist = []\n",
    "    for des in query_sift_descriptors_list:\n",
    "        if des is not None:\n",
    "            final_query_bovw_hist.append(query_bovw_hist[temp_bovw_hist_idx])\n",
    "            temp_bovw_hist_idx += 1\n",
    "        else:\n",
    "            final_query_bovw_hist.append(np.zeros(bovw_vocabulary.shape[0]))\n",
    "    query_bovw_hist = np.array(final_query_bovw_hist)\n",
    "    print(f\"  - BoVW Histogram ì°¨ì›: {query_bovw_hist.shape}\")\n",
    "else:\n",
    "    print(\"  âš ï¸ ì¿¼ë¦¬ ì´ë¯¸ì§€ì—ì„œ SIFT ë””ìŠ¤í¬ë¦½í„°ê°€ ì—†ì–´ BoVW Histogramì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 0 ë²¡í„°ë¡œ ì±„ì›ë‹ˆë‹¤.\")\n",
    "    query_bovw_hist = np.zeros((len(query_df), bovw_vocabulary.shape[0]))\n",
    "\n",
    "\n",
    "print(\"âœ” ì¿¼ë¦¬ ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ.\")\n",
    "\n",
    "# 3. ëª¨ë“  íŠ¹ì§• ê²°í•© (í•™ìŠµ ì‹œì™€ ë™ì¼í•œ ìˆœì„œì™€ ë°©ì‹ìœ¼ë¡œ ê²°í•©)\n",
    "query_X_features_list = [\n",
    "    query_features_color,\n",
    "    query_features_lbp,\n",
    "    query_features_hog,\n",
    "    query_bovw_hist\n",
    "]\n",
    "X_query_combined = combine_features(*query_X_features_list).astype(np.float32)\n",
    "\n",
    "print(f\"âœ” ì¿¼ë¦¬ ì´ë¯¸ì§€ í†µí•© íŠ¹ì§• ë²¡í„° ìƒì„± ì™„ë£Œ. Shape: {X_query_combined.shape}\")\n",
    "\n",
    "# 4. í•™ìŠµëœ Faiss KNN ëª¨ë¸ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰\n",
    "print(\"â³ ì¿¼ë¦¬ ì´ë¯¸ì§€ ì˜ˆì¸¡ ë° Top-N Accuracy ê³„ì‚° ì¤‘...\")\n",
    "\n",
    "# ì¿¼ë¦¬ ì´ë¯¸ì§€ì˜ ì‹¤ì œ ë¼ë²¨ ì¶”ì¶œ (load_images_from_folderì—ì„œ 'image_path'ë¥¼ ë°˜í™˜í•˜ë¯€ë¡œ ê°€ëŠ¥)\n",
    "# ê° ì´ë¯¸ì§€ì˜ ìƒìœ„ í´ë” ì´ë¦„ì´ ë¼ë²¨ì´ë¼ê³  ê°€ì •í•©ë‹ˆë‹¤.\n",
    "query_true_labels = [os.path.basename(os.path.dirname(path)) for path in query_df['image_path']]\n",
    "query_true_labels_encoded = le.transform(query_true_labels)\n",
    "\n",
    "\n",
    "# Top-10 ì˜ˆì¸¡ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸° (predict_faiss_knn_topk í•¨ìˆ˜ ì‚¬ìš©)\n",
    "D, I, predicted_neighbor_labels_top10 = predict_faiss_knn_topk(\n",
    "    faiss_index, train_labels_for_pred, X_query_combined, k=10\n",
    ")\n",
    "\n",
    "# Top-1 ì˜ˆì¸¡ ë¼ë²¨ (ê°€ì¥ ê°€ê¹Œìš´ ì´ì›ƒì˜ ë¼ë²¨)\n",
    "predicted_labels_encoded_top1 = predicted_neighbor_labels_top10[:, 0]\n",
    "predicted_labels_top1 = le.inverse_transform(predicted_labels_encoded_top1)\n",
    "\n",
    "print(\"âœ” ì¿¼ë¦¬ ì´ë¯¸ì§€ ì˜ˆì¸¡ ì™„ë£Œ.\")\n",
    "\n",
    "\n",
    "# 5. Accuracy ê³„ì‚°\n",
    "print(\"\\n--- Accuracy ê³„ì‚° ---\")\n",
    "\n",
    "# Top-1 Accuracy ê³„ì‚°\n",
    "correct_top1 = (predicted_labels_encoded_top1 == query_true_labels_encoded).sum()\n",
    "total_queries = len(query_df)\n",
    "top1_accuracy = correct_top1 / total_queries\n",
    "\n",
    "print(f\"ì´ ì¿¼ë¦¬ ì´ë¯¸ì§€ ê°œìˆ˜: {total_queries}ê°œ\")\n",
    "print(f\"Top-1 ì •ë‹µ ê°œìˆ˜: {correct_top1}ê°œ\")\n",
    "print(f\"Top-1 Accuracy: {top1_accuracy:.4f}\")\n",
    "\n",
    "task2_topk_accuracy = task2_score(query_true_labels_encoded, predicted_neighbor_labels_top10, topk=10)\n",
    "print(f\"Task2 Accuracy (Top-10 Same-Class): {task2_topk_accuracy:.4f}\")\n",
    "# --------------------------------------------------\n",
    "\n",
    "\n",
    "# 6. ì˜ˆì¸¡ ê²°ê³¼ ê°œë³„ ì¶œë ¥ (ì˜ˆì‹œ) - ì—¬ê¸°ì„œëŠ” Top-1 ê²°ê³¼ë§Œ ì¶œë ¥í•©ë‹ˆë‹¤.\n",
    "print(\"\\n--- ì¿¼ë¦¬ ì´ë¯¸ì§€ ì˜ˆì¸¡ ê²°ê³¼ (Top-1) ---\")\n",
    "import os # os ëª¨ë“ˆì´ ì„í¬íŠ¸ ë˜ì–´ìˆì§€ ì•Šì„ ê²½ìš°ë¥¼ ëŒ€ë¹„\n",
    "import matplotlib.pyplot as plt # pltë„ ì„í¬íŠ¸ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸\n",
    "for i, pred_label in enumerate(predicted_labels_top1):\n",
    "    image_identifier = os.path.basename(query_df['image_path'].iloc[i]) # íŒŒì¼ ì´ë¦„ìœ¼ë¡œ ì‹ë³„\n",
    "    true_label_name = le.inverse_transform([query_true_labels_encoded[i]])[0]\n",
    "    print(f\"ì¿¼ë¦¬ '{image_identifier}': ì‹¤ì œ ë¼ë²¨ = {true_label_name}, ì˜ˆì¸¡ ë¼ë²¨ (Top-1) = {pred_label}\")\n",
    "    \n",
    "    # ì´ë¯¸ì§€ ì‹œê°í™” (ì„ íƒ ì‚¬í•­)\n",
    "    #plt.imshow(cv2.cvtColor(query_df['image_data'].iloc[i], cv2.COLOR_BGR2RGB))\n",
    "    #plt.title(f\"Predicted (Top-1): {pred_label}\\nTrue: {true_label_name}\")\n",
    "    #plt.axis('off')\n",
    "    #plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
