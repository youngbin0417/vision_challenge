{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d30afab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bvb09\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm # 로컬에서는 tqdm.notebook 대신 일반 tqdm 사용\n",
    "from tqdm.contrib.concurrent import thread_map\n",
    "import joblib\n",
    "import random\n",
    "\n",
    "# skimage\n",
    "from skimage.exposure import rescale_intensity, equalize_hist\n",
    "from skimage.filters import gaussian\n",
    "from skimage.restoration import denoise_bilateral\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage.feature import local_binary_pattern, hog, graycomatrix, graycoprops\n",
    "from skimage.transform import resize\n",
    "from scipy import ndimage\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder,normalize\n",
    "from sklearn.metrics import pairwise_distances, silhouette_score, confusion_matrix\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "# joblib (병렬 처리를 위해)\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# faiss (KNN 가속화를 위해)\n",
    "import faiss\n",
    "\n",
    "# 데이터 관련 \n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a24971a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 특징 추출 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "def edge(img_bgr):\n",
    "    # 1) 강제 리사이즈\n",
    "    img_bgr = cv2.resize(img_bgr, (120, 120), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # 2) CLAHE → Gray → Blur → Denoise → Canny\n",
    "    lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(2.0, (8,8))\n",
    "    l = clahe.apply(l)\n",
    "    img_eq = cv2.cvtColor(cv2.merge((l,a,b)), cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    gray = cv2.cvtColor(img_eq, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "    denoised = cv2.fastNlMeansDenoising(blurred, h=10, templateWindowSize=7, searchWindowSize=21)\n",
    "    edges = cv2.Canny(denoised, 100, 230)   \n",
    "\n",
    "    return edges\n",
    "\n",
    "# 1) 공통: BGR → LAB → CLAHE(L) → BGR (필요 시)\n",
    "def apply_clahe(img_bgr):\n",
    "    lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    l = cv2.createCLAHE(2.0, (8,8)).apply(l)\n",
    "    return cv2.cvtColor(cv2.merge((l,a,b)), cv2.COLOR_LAB2BGR)\n",
    "\n",
    "# 3) Unsharp mask (SIFT 전용)\n",
    "def unsharp(img_gray):\n",
    "    blurred = cv2.GaussianBlur(img_gray, (3,3), 0)\n",
    "    return cv2.addWeighted(img_gray, 1.5, blurred, -0.5, 0)\n",
    "\n",
    "# 4) Mild Gaussian blur (LBP/GLCM/Laws)\n",
    "def mild_blur(img_gray):\n",
    "    return cv2.GaussianBlur(img_gray, (3,3), 0)\n",
    "def gray(img):\n",
    "    image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return image\n",
    "\n",
    "# ==============================================================================\n",
    "#  피쳐 추출 함수\n",
    "# ==================================================================:============\n",
    "\n",
    "def extract_color_histogram_features(image):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0,1,2], None, (8,8,8), [0,180,0,256,0,256])\n",
    "    return cv2.normalize(hist, hist).flatten()\n",
    "\n",
    "def extract_sift_pca_mean(img_bgr, pca_model=None, n_components=32):\n",
    "    img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(img_gray, None)\n",
    "\n",
    "    if descriptors is None or len(descriptors) == 0:\n",
    "        return np.zeros(n_components if pca_model else 128, dtype=np.float32)\n",
    "\n",
    "    if pca_model is None:\n",
    "        pca_model = PCA(n_components=n_components)\n",
    "        descriptors_pca = pca_model.fit_transform(descriptors)\n",
    "    else:\n",
    "        descriptors_pca = pca_model.transform(descriptors)\n",
    "\n",
    "    mean_vector = np.mean(descriptors_pca, axis=0)\n",
    "    return mean_vector.astype(np.float32)\n",
    "\n",
    "def extract_glcm_features(image):\n",
    "    if image is None:\n",
    "        num_props = 6\n",
    "        num_distances = 3\n",
    "        num_angles = 4\n",
    "        return np.zeros(num_props * num_distances * num_angles)\n",
    "        \n",
    "    img_glcm = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    img_glcm = mild_blur(img_glcm)\n",
    "    img_glcm = apply_clahe(cv2.cvtColor(img_glcm, cv2.COLOR_GRAY2BGR))\n",
    "    gray_image = cv2.cvtColor(img_glcm, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    distances = [1, 2, 3]\n",
    "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4]\n",
    "    \n",
    "    try:\n",
    "        glcm = graycomatrix(gray_image, distances=distances, angles=angles, symmetric=True, normed=True)\n",
    "        \n",
    "        props_to_extract = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation', 'ASM']\n",
    "        glcm_features = []\n",
    "        for prop in props_to_extract:\n",
    "            glcm_features.append(graycoprops(glcm, prop).ravel())\n",
    "            \n",
    "        return np.concatenate(glcm_features)\n",
    "    except Exception as e:\n",
    "        print(f\"GLCM 추출 중 오류 발생: {e}\")\n",
    "        num_props = 6\n",
    "        num_distances = len(distances) \n",
    "        num_angles = len(angles)   \n",
    "        return np.zeros(num_props * num_distances * num_angles)\n",
    "\n",
    "def extract_hog_features(image, orientations=9, pixels_per_cell=(16, 16), cells_per_block=(2, 2)):\n",
    "    img = cv2.resize(image, (120, 120), interpolation=cv2.INTER_AREA)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    features = hog(gray,\n",
    "                   orientations=orientations,\n",
    "                   pixels_per_cell=pixels_per_cell,\n",
    "                   cells_per_block=cells_per_block,\n",
    "                   block_norm='L2-Hys',\n",
    "                   visualize=False,\n",
    "                   transform_sqrt=True,\n",
    "                   feature_vector=True)\n",
    "    return features.astype(np.float32)\n",
    "\n",
    "def extract_sift_descriptors_from_array(image):\n",
    "    img = apply_clahe(image)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_image=unsharp(img)\n",
    "\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp, des = sift.detectAndCompute(gray_image, None)\n",
    "\n",
    "    return des\n",
    "\n",
    "def extract_lbp_features_from_array(image, P=8, R=1, method='uniform'):\n",
    "    image=apply_clahe(image)\n",
    "    image=mild_blur(image)\n",
    "    gray_image=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    lbp_image = local_binary_pattern(gray_image, P, R, method=method)\n",
    "\n",
    "    max_bins = P * (P - 1) + 3 if method == 'default' else P + 2\n",
    "    hist, _ = np.histogram(lbp_image.ravel(), bins=max_bins, range=(0, max_bins), density=True)\n",
    "    return hist\n",
    "\n",
    "\n",
    "# Laws' Texture Energy - 기존과 동일\n",
    "def extract_laws_energy_features(image, window_size=15):\n",
    "    image_gray=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image_gray=mild_blur(image_gray)\n",
    "\n",
    "    L5 = np.array([1, 4, 6, 4, 1], dtype=np.float32)\n",
    "    E5 = np.array([-1, -2, 0, 2, 1], dtype=np.float32)\n",
    "    S5 = np.array([-1, 0, 2, 0, -1], dtype=np.float32)\n",
    "    W5 = np.array([-1, 2, 0, -2, 1], dtype=np.float32)\n",
    "    R5 = np.array([1, -4, 6, -4, 1], dtype=np.float32)\n",
    "    kernels = [L5, E5, S5, W5, R5]\n",
    "\n",
    "    energy_features = []\n",
    "    if image_gray.dtype == np.uint8:\n",
    "        image_gray = image_gray.astype(np.float32)\n",
    "\n",
    "    for k1 in kernels:\n",
    "        for k2 in kernels:\n",
    "            kernel = np.outer(k1, k2)\n",
    "            filtered = ndimage.convolve(image_gray, kernel, mode='reflect')\n",
    "            energy = np.abs(filtered)\n",
    "            summed = cv2.boxFilter(energy, ddepth=-1, ksize=(window_size, window_size), normalize=False)\n",
    "            energy_features.append(summed.mean())\n",
    "\n",
    "    return np.array(energy_features, dtype=np.float32)\n",
    "\n",
    "\n",
    "def learn_bovw_vocabulary(all_sift_descriptors, num_clusters=200):\n",
    "    filtered = [des for des in all_sift_descriptors if des is not None and len(des) > 0]\n",
    "    feature_dims = {des.shape[1] for des in filtered}\n",
    "    if len(feature_dims) > 1:\n",
    "        raise ValueError(f\"❌ BoVW 학습용 SIFT 디스크립터들의 차원이 일치하지 않음: {feature_dims}\")\n",
    "\n",
    "    concatenated_descriptors = np.vstack(filtered)\n",
    "    \n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    flags = cv2.KMEANS_RANDOM_CENTERS\n",
    "    _, _, centers = cv2.kmeans(\n",
    "        concatenated_descriptors.astype(np.float32),\n",
    "        num_clusters, None, criteria, 10, flags\n",
    "    )\n",
    "    return centers\n",
    "\n",
    "def create_bovw_histogram(sift_descriptors, vocabulary):\n",
    "    num_clusters = vocabulary.shape[0]\n",
    "    if sift_descriptors is None or len(sift_descriptors) == 0:\n",
    "        return np.zeros(num_clusters, dtype=np.float32)\n",
    "\n",
    "    try:\n",
    "        distances = np.linalg.norm(\n",
    "            vocabulary[None, :, :] - sift_descriptors[:, None, :], axis=2\n",
    "        )\n",
    "        closest_clusters = np.argmin(distances, axis=1)\n",
    "        histogram = np.bincount(closest_clusters, minlength=num_clusters).astype(np.float32)\n",
    "        histogram = cv2.normalize(histogram, None, norm_type=cv2.NORM_L2).flatten()\n",
    "        return histogram\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ BoVW 히스토그램 생성 오류: {e}\")\n",
    "        return np.zeros(num_clusters, dtype=np.float32)\n",
    "\n",
    "\n",
    "def parallel_create_bovw_histograms(descriptor_list, vocabulary, n_jobs=6):\n",
    "    histograms = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(create_bovw_histogram)(desc, vocabulary) for desc in descriptor_list\n",
    "    )\n",
    "    return np.array(histograms, dtype=np.float32)\n",
    "\n",
    "print(\"✔ 특징 추출 함수 정의 완료\")\n",
    "\n",
    "# ==============================================================================\n",
    "#  분류 모델 및 학습/평가 함수\n",
    "# ==============================================================================\n",
    "# 유클리드 거리 기반 Faiss KNN 학습 (수정됨)\n",
    "\n",
    "def combine_features(*feature_arrays):\n",
    "    \"\"\"주어진 특징 배열들을 가로로 결합합니다.\"\"\"\n",
    "    return np.hstack(feature_arrays)\n",
    "\n",
    "def train_faiss_knn_euclidean(X_train, y_train, n_neighbors=3):\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    D = X_train.shape[1]\n",
    "\n",
    "    index = faiss.IndexFlatL2(D)\n",
    "    index.add(X_train)\n",
    "\n",
    "    return index, y_train, n_neighbors\n",
    "\n",
    "# 유클리드 거리 기반 Faiss KNN 예측 (수정됨)\n",
    "def predict_faiss_knn_euclidean(index, y_train_labels, n_neighbors, X_test):\n",
    "    X_test = X_test.astype(np.float32)\n",
    "\n",
    "    distances, indices = index.search(X_test, n_neighbors)\n",
    "\n",
    "    y_pred = []\n",
    "    for i in range(len(X_test)):\n",
    "        neighbor_labels = y_train_labels[indices[i]]\n",
    "        unique_labels, counts = np.unique(neighbor_labels, return_counts=True)\n",
    "        predicted_label = unique_labels[np.argmax(counts)]\n",
    "        y_pred.append(predicted_label)\n",
    "    return np.array(y_pred)\n",
    "\n",
    "# 기존 predict_faiss_knn_euclidean 함수를 수정하거나, 아래 함수를 추가합니다.\n",
    "# 이 함수는 k개의 가장 가까운 이웃의 라벨을 반환합니다.\n",
    "def predict_faiss_knn_topk(faiss_index, train_labels_encoded, query_features, k=10):\n",
    "    if faiss_index is None:\n",
    "        raise ValueError(\"Faiss 인덱스가 학습되지 않았습니다.\")\n",
    "    if query_features.shape[0] == 0:\n",
    "        return np.array([]), np.array([]), np.array([])\n",
    "\n",
    "    D, I = faiss_index.search(query_features, k)\n",
    "    predicted_neighbor_labels = train_labels_encoded[I]\n",
    "\n",
    "    return D, I, predicted_neighbor_labels\n",
    "\n",
    "# 참고: 기존 predict_faiss_knn_euclidean 함수는 단순히 k=1로 설정하고 첫 번째 라벨을 반환하는 식으로 동작할 수 있습니다.\n",
    "# 만약 기존 predict_faiss_knn_euclidean 함수가 k를 인자로 받는다면, 그 함수를 활용해도 좋습니다.\n",
    "# 여기서는 Top-k 결과를 직접 다룰 수 있도록 predict_faiss_knn_topk를 사용합니다.\n",
    "\n",
    "# Task2 Accuracy (Top-K Same-Class)를 계산하는 함수\n",
    "def task2_score(y_true, topk_preds, topk=10):\n",
    "    match_counts = []\n",
    "    for true_label, pred_list_np in zip(y_true, topk_preds):\n",
    "        # NumPy 배열을 Python 리스트로 변환하여 .count() 메서드 사용\n",
    "        pred_list = pred_list_np.tolist()\n",
    "        # topk_preds의 각 요소(pred_list)는 실제 라벨이 포함된 횟수 / topk\n",
    "        # 예를 들어, topk=10일 때, 'car' 라벨이 3번 등장하면 3/10 = 0.3\n",
    "        match_counts.append(pred_list.count(true_label) / topk)\n",
    "    return np.mean(match_counts)\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, title='Confusion Matrix', normalize=False):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\".2f\" if normalize else \"d\", cmap=\"Blues\",\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1b431ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔹 경로 설정\n",
    "MODEL_DIR = './model_outputs2'\n",
    "QUERY_IMAGE_DIR = 'C:/Users/bvb09/Downloads/query/query'  # <- 여기에 쿼리 이미지 폴더 넣기\n",
    "\n",
    "# 🔹 모델 및 도구 불러오기\n",
    "faiss_index = faiss.read_index(os.path.join(MODEL_DIR, 'faiss_index.idx'))\n",
    "le = joblib.load(os.path.join(MODEL_DIR, 'label_encoder.pkl'))\n",
    "pca_hog = joblib.load(os.path.join(MODEL_DIR, 'pca_hog.pkl'))\n",
    "pca_sift = joblib.load(os.path.join(MODEL_DIR, 'pca_sift.pkl'))\n",
    "bovw_vocabulary = np.load(os.path.join(MODEL_DIR, 'bovw_vocabulary.npy'))\n",
    "train_labels_for_pred = joblib.load(os.path.join(MODEL_DIR, 'labels.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eade782e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ================================\n",
    "# 1. 쿼리 이미지 로드 (라벨 없음)\n",
    "# ================================\n",
    "def load_images_nolabel(folder_path, resize_to=(120, 120)):\n",
    "    \"\"\"\n",
    "    폴더 내 모든 이미지를 로드하고 (옵션) 리사이즈해서 리스트로 반환\n",
    "    \"\"\"\n",
    "    images, image_paths = [], []\n",
    "    valid_exts = ('.jpg', '.jpeg', '.png', '.bmp', '.gif')\n",
    "\n",
    "    for fname in os.listdir(folder_path):\n",
    "        if fname.lower().endswith(valid_exts):\n",
    "            img_path = os.path.join(folder_path, fname)\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is not None:\n",
    "                if resize_to is not None:\n",
    "                    img = cv2.resize(img, resize_to, interpolation=cv2.INTER_AREA)\n",
    "                images.append(img)\n",
    "                image_paths.append(img_path)\n",
    "            else:\n",
    "                print(f\"⚠️ 이미지 로드 실패: {img_path}\")\n",
    "\n",
    "    return images, image_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab8006eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 쿼리 이미지 100장 로드 완료.\n"
     ]
    }
   ],
   "source": [
    "# 🔹 이미지 로딩\n",
    "images, image_paths = load_images_nolabel(QUERY_IMAGE_DIR)\n",
    "print(f\"✔ 쿼리 이미지 {len(images)}장 로드 완료.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75d256e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Color: 100%|██████████| 100/100 [00:00<00:00, 14291.62it/s]\n",
      "LAWS: 100%|██████████| 100/100 [00:00<00:00, 176.42it/s]\n",
      "HOG: 100%|██████████| 100/100 [00:00<00:00, 835.83it/s]\n",
      "SIFT: 100%|██████████| 100/100 [00:00<00:00, 321.93it/s]\n"
     ]
    }
   ],
   "source": [
    "features_color = np.array([extract_color_histogram_features(img) for img in tqdm(images, desc=\"Color\")])\n",
    "features_laws = np.array([extract_laws_energy_features(img) for img in tqdm(images, desc=\"LAWS\")])\n",
    "hog_list = [extract_hog_features(img) for img in tqdm(images, desc=\"HOG\")]\n",
    "features_hog = pca_hog.transform(np.vstack(hog_list))\n",
    "\n",
    "sift_des_list = [extract_sift_descriptors_from_array(img) for img in tqdm(images, desc=\"SIFT\")]\n",
    "sift_des_list = [\n",
    "    pca_sift.transform(d) if d is not None and d.shape[1] == 128 else None\n",
    "    for d in sift_des_list\n",
    "]\n",
    "\n",
    "valid_des = [d for d in sift_des_list if d is not None]\n",
    "bovw_hist_partial = parallel_create_bovw_histograms(valid_des, bovw_vocabulary, n_jobs=-1)\n",
    "\n",
    "bovw_hist = []\n",
    "idx = 0\n",
    "for d in sift_des_list:\n",
    "    if d is not None:\n",
    "        bovw_hist.append(bovw_hist_partial[idx])\n",
    "        idx += 1\n",
    "    else:\n",
    "        bovw_hist.append(np.zeros(bovw_vocabulary.shape[0]))\n",
    "bovw_hist = np.array(bovw_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ac6aaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✔ Top-10 예측 완료: (100, 10)\n",
      "✅ Top-1 예측 결과 저장 완료: ./model_outputs2\\c1_t1_a2.csv\n",
      "✅ Top-10 예측 결과 CSV 저장 완료: ./model_outputs2\\c1_t2_a2.csv\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# 4. 특징 벡터 결합 및 예측\n",
    "# ================================\n",
    "X_combined = combine_features(features_color, features_laws, features_hog, bovw_hist).astype(np.float32)\n",
    "\n",
    "# 🔹 Faiss로 Top-K 예측 수행\n",
    "topk = 10\n",
    "D, I, predicted_neighbor_labels_topk = predict_faiss_knn_topk(\n",
    "    faiss_index, train_labels_for_pred, X_combined, k=topk\n",
    ")\n",
    "\n",
    "# 🔹 Top-1 예측 결과 (가장 가까운 이웃의 라벨)\n",
    "predicted_labels_encoded_top1 = predicted_neighbor_labels_topk[:, 0]\n",
    "\n",
    "print(f\"\\n✔ Top-{topk} 예측 완료: {predicted_neighbor_labels_topk.shape}\")\n",
    "\n",
    "# ================================\n",
    "# 5. 평가 지표 출력\n",
    "# ================================\n",
    "# 🔹 Top-1 예측 라벨 (문자열)\n",
    "predicted_labels_top1 = le.inverse_transform(predicted_labels_encoded_top1)\n",
    "\n",
    "# 🔹 이미지 파일명만 추출\n",
    "image_names = [os.path.basename(path) for path in image_paths]\n",
    "\n",
    "# 🔹 결과 DataFrame\n",
    "results_simple_df = pd.DataFrame({\n",
    "    'image': image_names,\n",
    "    'predicted_label': predicted_labels_top1\n",
    "})\n",
    "\n",
    "# 🔹 저장\n",
    "csv_path = os.path.join(MODEL_DIR, 'c1_t1_a2.csv')\n",
    "results_simple_df.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"✅ Top-1 예측 결과 저장 완료: {csv_path}\")\n",
    "\n",
    "# 🔹 확인\n",
    "results_simple_df.head()\n",
    "\n",
    "# 🔹 라벨 문자열 변환\n",
    "topk_labels_str = [le.inverse_transform(row) for row in predicted_neighbor_labels_topk]\n",
    "\n",
    "# 🔹 파일 이름만 추출\n",
    "image_names = [os.path.basename(p) for p in image_paths]\n",
    "\n",
    "# 🔹 DataFrame 생성\n",
    "topk_df = pd.DataFrame(topk_labels_str)\n",
    "topk_df.insert(0, 'image', image_names)  # 첫 열에 이미지 이름 추가\n",
    "\n",
    "# 🔹 저장\n",
    "csv_path = os.path.join(MODEL_DIR, 'c1_t2_a2.csv')\n",
    "topk_df.to_csv(csv_path, index=False, encoding='utf-8-sig')\n",
    "print(f\"✅ Top-10 예측 결과 CSV 저장 완료: {csv_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
