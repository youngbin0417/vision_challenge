{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bvb09\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 모든 라이브러리 임포트 완료!\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "#  라이브러리 임포트\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm # 로컬에서는 tqdm.notebook 대신 일반 tqdm 사용\n",
    "from tqdm.contrib.concurrent import thread_map\n",
    "import joblib\n",
    "import random\n",
    "\n",
    "# skimage\n",
    "from skimage.exposure import rescale_intensity, equalize_hist\n",
    "from skimage.filters import gaussian\n",
    "from skimage.restoration import denoise_bilateral\n",
    "from skimage.util import img_as_ubyte\n",
    "from skimage.feature import local_binary_pattern, hog, graycomatrix, graycoprops\n",
    "from skimage.transform import resize\n",
    "from scipy import ndimage\n",
    "\n",
    "# sklearn\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, classification_report, f1_score\n",
    "from sklearn.preprocessing import LabelEncoder,normalize\n",
    "from sklearn.metrics import pairwise_distances, silhouette_score, confusion_matrix\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "# joblib (병렬 처리를 위해)\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# faiss (KNN 가속화를 위해)\n",
    "import faiss\n",
    "\n",
    "# 데이터 관련 \n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ensemble\n",
    "from Ensemble import EnsembleFaissKNN\n",
    "\n",
    "#DATASET_BASE_PATH = \"C:/Users/bvb09/.cache/kagglehub/datasets/mikhailma/test-dataset/versions/1/Google_Recaptcha_V2_Images_Dataset\"\n",
    "\n",
    "print(\"✔ 모든 라이브러리 임포트 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "#  데이터 로드 함수\n",
    "# ==============================================================================\n",
    "\n",
    "# 이미지 로드 함수\n",
    "def load_images_from_folder(base_path):\n",
    "    images = []\n",
    "    labels = []\n",
    "    image_folder_path = os.path.join(base_path, 'images')\n",
    "    \n",
    "    if not os.path.exists(image_folder_path):\n",
    "        raise FileNotFoundError(f\"이미지 폴더를 찾을 수 없습니다: {image_folder_path}\\n\"\n",
    "                                f\"DATASET_BASE_PATH를 올바르게 설정했는지 확인해주세요.\")\n",
    "\n",
    "    for label_name in tqdm(os.listdir(image_folder_path), desc=\"폴더 로드 중\"):\n",
    "        label_path = os.path.join(image_folder_path, label_name)\n",
    "        if os.path.isdir(label_path):\n",
    "            for img_name in os.listdir(label_path):\n",
    "                img_path = os.path.join(label_path, img_name)\n",
    "                try:\n",
    "                    img = cv2.imread(img_path)\n",
    "                    if img is not None:\n",
    "                        images.append(img)\n",
    "                        labels.append(label_name)\n",
    "                    else:\n",
    "                        print(f\"경고: {img_path} 이미지를 로드할 수 없습니다.\")\n",
    "                except Exception as e:\n",
    "                    print(f\"경고: {img_path} 로딩 중 오류 발생 - {e}\")\n",
    "    return pd.DataFrame({'image_data': images, 'label': labels})\n",
    "\n",
    "def visualize_features(X_feats, y_labels, method='pca'):\n",
    "    if method == 'pca':\n",
    "        reducer = PCA(n_components=2)\n",
    "    else:\n",
    "        from sklearn.manifold import TSNE\n",
    "        reducer = TSNE(n_components=2, random_state=42)\n",
    "\n",
    "    X_reduced = reducer.fit_transform(X_feats)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    scatter = plt.scatter(X_reduced[:, 0], X_reduced[:, 1], c=y_labels, cmap='tab20', s=10, alpha=0.7)\n",
    "    plt.title(f'Feature Distribution via {method.upper()}')\n",
    "    plt.colorbar(scatter, ticks=range(len(set(y_labels))))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge(img_bgr):\n",
    "    # 1) 강제 리사이즈\n",
    "    img_bgr = cv2.resize(img_bgr, (120, 120), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # 2) CLAHE → Gray → Blur → Denoise → Canny\n",
    "    lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    clahe = cv2.createCLAHE(2.0, (8,8))\n",
    "    l = clahe.apply(l)\n",
    "    img_eq = cv2.cvtColor(cv2.merge((l,a,b)), cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    gray = cv2.cvtColor(img_eq, cv2.COLOR_BGR2GRAY)\n",
    "    blurred = cv2.GaussianBlur(gray, (3,3), 0)\n",
    "    denoised = cv2.fastNlMeansDenoising(blurred, h=10, templateWindowSize=7, searchWindowSize=21)\n",
    "    edges = cv2.Canny(denoised, 100, 230)\n",
    "\n",
    "    #plt.imshow(edges, cmap='gray')\n",
    "    #plt.title(\"Preprocessed\")\n",
    "    #plt.axis('off')\n",
    "    #plt.show()\n",
    "    return edges  # 항상 (IMG_SIZE, IMG_SIZE)\n",
    "\n",
    "# 1) 공통: BGR → LAB → CLAHE(L) → BGR (필요 시)\n",
    "def apply_clahe(img_bgr):\n",
    "    lab = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "    l = cv2.createCLAHE(2.0, (8,8)).apply(l)\n",
    "    return cv2.cvtColor(cv2.merge((l,a,b)), cv2.COLOR_LAB2BGR)\n",
    "\n",
    "# 3) Unsharp mask (SIFT 전용)\n",
    "def unsharp(img_gray):\n",
    "    blurred = cv2.GaussianBlur(img_gray, (3,3), 0)\n",
    "    return cv2.addWeighted(img_gray, 1.5, blurred, -0.5, 0)\n",
    "\n",
    "# 4) Mild Gaussian blur (LBP/GLCM/Laws)\n",
    "def mild_blur(img_gray):\n",
    "    return cv2.GaussianBlur(img_gray, (3,3), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gray(img):\n",
    "    image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkcol(img_bgr):\n",
    "    #image = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    #image=cv2.GaussianBlur(image, ksize=(3,3), sigmaX=0)\n",
    "    #image = cv2.cvtColor(image, cv2.COLOR_GRAY2RGB)\n",
    "    #image = cv2.cvtColor(img_bgr, cv2.COLOR_GRAY2BGR)\n",
    "    hsv = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0, 1, 2], None, (8,8,8), [0,180, 0,256, 0,256])\n",
    "    hist = cv2.normalize(hist, hist).flatten()\n",
    "    h, s, v = cv2.split(hsv)\n",
    "    rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
    "    hist_rgb = cv2.calcHist([rgb], [0, 1, 2], None, (8,8,8), [0,256, 0,256, 0,256])\n",
    "    hist_rgb = cv2.normalize(hist_rgb, hist_rgb).flatten()\n",
    "    hist_bgr = cv2.calcHist([img_bgr], [0, 1, 2], None, (8,8,8), [0,256, 0,256, 0,256])\n",
    "    hist_bgr = cv2.normalize(hist_bgr, hist_bgr).flatten()\n",
    "    #plt.imshow(v)\n",
    "    #plt.title(\"Color\")\n",
    "    #plt.axis('off')\n",
    "    #plt.show()\n",
    "     # ✅ 2D 시각화\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(hist, color='blue')\n",
    "    plt.title(\"Flattened HSV Histogram\")\n",
    "    plt.xlabel(\"Bin Index\")\n",
    "    plt.ylabel(\"Normalized Value\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    return hsv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "폴더 로드 중: 100%|██████████| 1/1 [00:00<00:00, 124.96it/s]\n",
      "이미지 전처리: 100%|██████████| 8/8 [00:00<00:00, 24.16it/s]\n"
     ]
    }
   ],
   "source": [
    "tst = \"C:/Users/bvb09/.cache/kagglehub/datasets/pre\"\n",
    "timg = load_images_from_folder(tst)\n",
    "timg['processed_image_data'] = [edge(img) for img in tqdm(timg['image_data'], desc=\"이미지 전처리\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 특징 추출 함수 정의 완료\n"
     ]
    }
   ],
   "source": [
    "# ==============================================================================\n",
    "#  피쳐 추출 함수\n",
    "# ==================================================================:============\n",
    "\n",
    "def extract_color_histogram_features(image):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist = cv2.calcHist([hsv], [0,1,2], None, (8,8,8), [0,180,0,256,0,256])\n",
    "    return cv2.normalize(hist, hist).flatten()\n",
    "\n",
    "def extract_sift_pca_mean(img_bgr, pca_model=None, n_components=32):\n",
    "    # 1. BGR → GRAY\n",
    "    img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # 2. SIFT 생성 및 디스크립터 추출\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(img_gray, None)\n",
    "\n",
    "    if descriptors is None or len(descriptors) == 0:\n",
    "        # 디스크립터 없을 경우 0 벡터 반환\n",
    "        return np.zeros(n_components if pca_model else 128, dtype=np.float32)\n",
    "\n",
    "    # 3. PCA 처리\n",
    "    if pca_model is None:\n",
    "        # PCA 학습도 포함 (보통 학습셋에서 따로 학습하는 게 좋음)\n",
    "        pca_model = PCA(n_components=n_components)\n",
    "        descriptors_pca = pca_model.fit_transform(descriptors)\n",
    "    else:\n",
    "        descriptors_pca = pca_model.transform(descriptors)\n",
    "\n",
    "    # 4. 평균 벡터 반환\n",
    "    mean_vector = np.mean(descriptors_pca, axis=0)\n",
    "    return mean_vector.astype(np.float32)\n",
    "\n",
    "def extract_glcm_features(image):\n",
    "    if image is None:\n",
    "        num_props = 6\n",
    "        num_distances = 3 # 아래 distances 리스트 길이\n",
    "        num_angles = 4    # 아래 angles 리스트 길이\n",
    "        return np.zeros(num_props * num_distances * num_angles)\n",
    "    \n",
    "    img_glcm = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    img_glcm = mild_blur(img_glcm)\n",
    "    img_glcm = apply_clahe(cv2.cvtColor(img_glcm, cv2.COLOR_GRAY2BGR))\n",
    "    gray_image = cv2.cvtColor(img_glcm, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    distances = [1, 2, 3] # 예시 거리 값\n",
    "    angles = [0, np.pi/4, np.pi/2, 3*np.pi/4] # 예시 각도 값\n",
    "    \n",
    "    try:\n",
    "        glcm = graycomatrix(gray_image, distances=distances, angles=angles, symmetric=True, normed=True)\n",
    "        \n",
    "        props_to_extract = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation', 'ASM']\n",
    "        glcm_features = []\n",
    "        for prop in props_to_extract:\n",
    "            glcm_features.append(graycoprops(glcm, prop).ravel())\n",
    "            \n",
    "        return np.concatenate(glcm_features)\n",
    "    except Exception as e:\n",
    "        # 오류 발생 시 처리 (예: 0으로 채워진 배열 반환)\n",
    "        print(f\"GLCM 추출 중 오류 발생: {e}\")\n",
    "        num_props = 6\n",
    "        num_distances = len(distances) \n",
    "        num_angles = len(angles)    \n",
    "        return np.zeros(num_props * num_distances * num_angles)\n",
    "\n",
    "def extract_hog_features(image, orientations=9, pixels_per_cell=(16, 16), cells_per_block=(2, 2)):\n",
    "     # 1) 리사이즈\n",
    "    img = cv2.resize(image, (120, 120), interpolation=cv2.INTER_AREA)\n",
    "    # 2) 그레이스케일 변환\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    features = hog(gray,\n",
    "                   orientations=orientations,\n",
    "                   pixels_per_cell=pixels_per_cell,\n",
    "                   cells_per_block=cells_per_block,\n",
    "                   block_norm='L2-Hys',\n",
    "                   visualize=False,\n",
    "                   transform_sqrt=True,\n",
    "                   feature_vector=True)\n",
    "    return features.astype(np.float32)\n",
    "\n",
    "def extract_sift_descriptors_from_array(image):\n",
    "    img = apply_clahe(image)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    gray_image=unsharp(img)\n",
    "\n",
    "    sift = cv2.SIFT_create()\n",
    "    kp, des = sift.detectAndCompute(gray_image, None) # 키포인트와 디스크립터 계산\n",
    "\n",
    "    return des # 디스크립터가 없을 경우 None 반환\n",
    "\n",
    "def extract_lbp_features_from_array(image, P=8, R=1, method='uniform'):\n",
    "    \n",
    "    image=apply_clahe(image)\n",
    "    #image=mild_blur(image)\n",
    "    gray_image=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    # local_binary_pattern 함수는 float 타입 이미지를 선호하지만, skimage는 UBYTE도 처리\n",
    "    lbp_image = local_binary_pattern(gray_image, P, R, method=method)\n",
    "\n",
    "    # LBP 히스토그램 계산\n",
    "    max_bins = P * (P - 1) + 3 if method == 'default' else P + 2 # uniform의 경우 P+2\n",
    "    hist, _ = np.histogram(lbp_image.ravel(), bins=max_bins, range=(0, max_bins), density=True)\n",
    "    return hist\n",
    "\n",
    "# Laws' Texture Energy - 기존과 동일\n",
    "def extract_laws_energy_features(image, window_size=15):\n",
    "    image_gray=cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image_gray=mild_blur(image_gray)\n",
    "\n",
    "    L5 = np.array([1, 4, 6, 4, 1], dtype=np.float32)\n",
    "    E5 = np.array([-1, -2, 0, 2, 1], dtype=np.float32)\n",
    "    S5 = np.array([-1, 0, 2, 0, -1], dtype=np.float32)\n",
    "    W5 = np.array([-1, 2, 0, -2, 1], dtype=np.float32)\n",
    "    R5 = np.array([1, -4, 6, -4, 1], dtype=np.float32)\n",
    "    kernels = [L5, E5, S5, W5, R5]\n",
    "\n",
    "    energy_features = []\n",
    "    if image_gray.dtype == np.uint8:\n",
    "        image_gray = image_gray.astype(np.float32)\n",
    "\n",
    "    for k1 in kernels:\n",
    "        for k2 in kernels:\n",
    "            kernel = np.outer(k1, k2)\n",
    "            filtered = ndimage.convolve(image_gray, kernel, mode='reflect')\n",
    "            energy = np.abs(filtered)\n",
    "            summed = cv2.boxFilter(energy, ddepth=-1, ksize=(window_size, window_size), normalize=False)\n",
    "            energy_features.append(summed.mean())\n",
    "\n",
    "    return np.array(energy_features, dtype=np.float32)\n",
    "\n",
    "def learn_bovw_vocabulary(all_sift_descriptors, num_clusters=200):\n",
    "    \"\"\"\n",
    "    Bag of Visual Words (BoVW)를 위한 시각적 단어(Vocabulary)를 학습합니다.\n",
    "    \"\"\"\n",
    "    filtered = [des for des in all_sift_descriptors if des is not None and len(des) > 0]\n",
    "\n",
    "    # ✔ 차원 확인: 모든 디스크립터의 feature 차원이 같아야 함\n",
    "    feature_dims = {des.shape[1] for des in filtered}\n",
    "    if len(feature_dims) > 1:\n",
    "        raise ValueError(f\"❌ BoVW 학습용 SIFT 디스크립터들의 차원이 일치하지 않음: {feature_dims}\")\n",
    "\n",
    "    concatenated_descriptors = np.vstack(filtered)\n",
    "    \n",
    "    criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 10, 1.0)\n",
    "    flags = cv2.KMEANS_RANDOM_CENTERS\n",
    "    _, _, centers = cv2.kmeans(\n",
    "        concatenated_descriptors.astype(np.float32),\n",
    "        num_clusters, None, criteria, 10, flags\n",
    "    )\n",
    "    return centers\n",
    "\n",
    "\n",
    "def create_bovw_histogram(sift_descriptors, vocabulary):\n",
    "    \"\"\"\n",
    "    단일 이미지의 SIFT → BoVW 히스토그램 (벡터화 버전)\n",
    "    \"\"\"\n",
    "    num_clusters = vocabulary.shape[0]\n",
    "    if sift_descriptors is None or len(sift_descriptors) == 0:\n",
    "        return np.zeros(num_clusters, dtype=np.float32)\n",
    "\n",
    "    try:\n",
    "        # ✔ 유클리디언 거리 계산 (벡터화)\n",
    "        distances = np.linalg.norm(\n",
    "            vocabulary[None, :, :] - sift_descriptors[:, None, :], axis=2\n",
    "        )  # shape: (num_des, num_clusters)\n",
    "\n",
    "        closest_clusters = np.argmin(distances, axis=1)\n",
    "        histogram = np.bincount(closest_clusters, minlength=num_clusters).astype(np.float32)\n",
    "        histogram = cv2.normalize(histogram, None, norm_type=cv2.NORM_L2).flatten()\n",
    "        return histogram\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ BoVW 히스토그램 생성 오류: {e}\")\n",
    "        return np.zeros(num_clusters, dtype=np.float32)\n",
    "\n",
    "\n",
    "def parallel_create_bovw_histograms(descriptor_list, vocabulary, n_jobs=6):\n",
    "    \"\"\"\n",
    "    여러 이미지의 SIFT → BoVW 히스토그램 (멀티프로세싱)\n",
    "    \"\"\"\n",
    "    histograms = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(create_bovw_histogram)(desc, vocabulary) for desc in descriptor_list\n",
    "    )\n",
    "    return np.array(histograms, dtype=np.float32)\n",
    "\n",
    "print(\"✔ 특징 추출 함수 정의 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_for_split(df, image_dir, bovw_vocabulary=None, num_bovw_clusters=200):\n",
    "\n",
    "    hog_feats = []\n",
    "    color_feats = []\n",
    "    lbp_feats = []\n",
    "    sift_descriptors_raw = [] # SIFT 디스크립터만\n",
    "\n",
    "    dataset_name = df.name if hasattr(df, 'name') else 'dataset'\n",
    "    print(f\"Loading images and extracting raw features for {dataset_name}...\")\n",
    "\n",
    "    # 이미지를 한 번 로드하고, 이를 각 특징 추출 함수에 전달\n",
    "    for img_name in tqdm(df['image_name'], desc=f\"Processing images for {dataset_name}\"):\n",
    "        img_path = os.path.join(image_dir, img_name)\n",
    "        image = cv2.imread(img_path)\n",
    "        if image is None:\n",
    "            raise FileNotFoundError(f\"Image not found at {img_path}\")\n",
    "\n",
    "        # 모든 이미지가 이미 120x120으로 리사이즈되었다고 가정하므로, 추가 리사이즈 없음\n",
    "        # 다만, cv2.imread는 BGR로 읽으므로, 컬러 히스토그램을 위해 RGB 변환은 필요\n",
    "        image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # RGB 변환은 여기서 한 번만 수행\n",
    "\n",
    "        # 각 특징 추출 함수에 이미지 배열 전달\n",
    "        hog_feats.append(extract_hog_features(image_rgb)) # HOG는 내부에서 GRAY 변환\n",
    "        color_feats.append(extract_color_histogram_features(image_rgb))\n",
    "        lbp_feats.append(extract_lbp_features_from_array(image_rgb)) # LBP는 내부에서 GRAY 변환\n",
    "        sift_descriptors_raw.append(extract_sift_descriptors_from_array(image_rgb)) # SIFT는 내부에서 GRAY 변환\n",
    "\n",
    "\n",
    "    current_bovw_vocab = bovw_vocabulary\n",
    "    if current_bovw_vocab is None: # 학습 데이터에서만 Vocabulary 학습\n",
    "        print(f\"Learning BoVW vocabulary for {dataset_name}...\")\n",
    "        current_bovw_vocab = learn_bovw_vocabulary(sift_descriptors_raw, num_clusters=num_bovw_clusters)\n",
    "        print(f\"BoVW vocabulary learned with {current_bovw_vocab.shape[0]} clusters.\")\n",
    "\n",
    "    all_bovw_feats = []\n",
    "    print(f\"Creating BoVW histograms for {dataset_name}...\")\n",
    "    for sift_des in tqdm(sift_descriptors_raw):\n",
    "        all_bovw_feats.append(create_bovw_histogram(sift_des, current_bovw_vocab))\n",
    "\n",
    "    return (np.array(hog_feats), np.array(color_feats),\n",
    "            np.array(all_bovw_feats), np.array(lbp_feats), current_bovw_vocab)\n",
    "\n",
    "\n",
    "def combine_features(*feature_arrays):\n",
    "    reshaped = []\n",
    "    for arr in feature_arrays:\n",
    "        arr = np.asarray(arr)\n",
    "        if arr.ndim == 3:\n",
    "            # (N, H, W) → (N, H*W)\n",
    "            arr = arr.reshape(arr.shape[0], -1)\n",
    "        elif arr.ndim == 1:\n",
    "            # (D,) → (1, D)\n",
    "            arr = arr.reshape(1, -1)\n",
    "        reshaped.append(arr)\n",
    "    return np.hstack(reshaped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "#  분류 모델 및 학습/평가 함수\n",
    "# ==============================================================================\n",
    "# 유클리드 거리 기반 Faiss KNN 학습 (수정됨)\n",
    "def train_faiss_knn_euclidean(X_train, y_train, n_neighbors=3):\n",
    "    # 유클리드 거리 기반에서는 데이터 정규화가 필요 없습니다.\n",
    "    # X_train = normalize(X_train, axis=1) # 이 줄을 주석 처리하거나 삭제합니다.\n",
    "    X_train = X_train.astype(np.float32)\n",
    "    D = X_train.shape[1]\n",
    "\n",
    "    # Inner Product (IP) 대신 L2 거리를 사용하는 인덱스를 생성합니다.\n",
    "    index = faiss.IndexFlatL2(D) # <-- 변경된 부분\n",
    "    index.add(X_train)\n",
    "\n",
    "    return index, y_train, n_neighbors\n",
    "\n",
    "# 유클리드 거리 기반 Faiss KNN 예측 (수정됨)\n",
    "def predict_faiss_knn_euclidean(index, y_train_labels, n_neighbors, X_test):\n",
    "    # 유클리드 거리 기반에서는 테스트 데이터 정규화도 필요 없습니다.\n",
    "    # X_test = normalize(X_test, axis=1) # 이 줄을 주석 처리하거나 삭제합니다.\n",
    "    X_test = X_test.astype(np.float32)\n",
    "\n",
    "    # search 결과는 D (거리)와 I (인덱스)입니다.\n",
    "    # L2 거리이므로 거리가 작을수록 가까운 것입니다.\n",
    "    distances, indices = index.search(X_test, n_neighbors) # <-- 이름 변경 (similarities -> distances)\n",
    "\n",
    "    y_pred = []\n",
    "    for i in range(len(X_test)):\n",
    "        neighbor_labels = y_train_labels[indices[i]]\n",
    "        # 거리 기반이므로 가장 가까운 이웃들의 레이블을 통해 다수결 투표\n",
    "        unique_labels, counts = np.unique(neighbor_labels, return_counts=True)\n",
    "        predicted_label = unique_labels[np.argmax(counts)]\n",
    "        y_pred.append(predicted_label)\n",
    "    return np.array(y_pred)\n",
    "\n",
    "def predict_faiss_knn_euclidean_topk(index, y_train_labels, n_neighbors, X_test):\n",
    "    \"\"\"\n",
    "    Faiss Top-K 예측 레이블 리스트 반환 (예: k=10일 때 각 샘플마다 10개 레이블 리스트)\n",
    "    \"\"\"\n",
    "    X_test = X_test.astype(np.float32)\n",
    "    distances, indices = index.search(X_test, n_neighbors)\n",
    "\n",
    "    topk_labels = []\n",
    "    for i in range(len(X_test)):\n",
    "        neighbor_labels = y_train_labels[indices[i]]\n",
    "        topk_labels.append(neighbor_labels.tolist())\n",
    "    return topk_labels\n",
    "\n",
    "def task2_score(y_true, topk_preds, topk=10):\n",
    "    \"\"\"\n",
    "    각 샘플마다 Top-10 예측 중 정답이 몇 번 포함되었는지 → 평균 비율 반환\n",
    "    \"\"\"\n",
    "    match_counts = [\n",
    "        pred_list.count(true_label) / topk\n",
    "        for true_label, pred_list in zip(y_true, topk_preds)\n",
    "    ]\n",
    "    return np.mean(match_counts)\n",
    "\n",
    "# test() 함수\n",
    "def test(model_tuple, X_test, y_test, average='weighted', topk=10):\n",
    "    faiss_index, y_train_labels, n_neighbors = model_tuple\n",
    "    \n",
    "    print(f\"  ▶ KNN 예측 중 (Faiss 사용, k={n_neighbors})...\")\n",
    "    \n",
    "    # Top-1 예측 (기존)\n",
    "    y_pred = predict_faiss_knn_euclidean(faiss_index, y_train_labels, n_neighbors, X_test)\n",
    "\n",
    "    # Top-k 예측\n",
    "    topk_labels = predict_faiss_knn_euclidean_topk(faiss_index, y_train_labels, topk, X_test)\n",
    "\n",
    "    # Top-10 Accuracy 계산\n",
    "    topk_hits = [true in pred_list for true, pred_list in zip(y_test, topk_labels)]\n",
    "    topk_acc = np.mean(topk_hits)\n",
    "\n",
    "    print(\"  ✔ 예측 완료.\")\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred, average=average, zero_division=0)\n",
    "    rec  = recall_score(y_test, y_pred, average=average, zero_division=0)\n",
    "\n",
    "    print(f\"[Top-1 Accuracy]  {acc:.4f}\")\n",
    "    print(f\"[Top-{topk} Accuracy] {topk_acc:.4f}\")\n",
    "    print(classification_report(y_test, y_pred, target_names=le.classes_))\n",
    "    print(f\"[Task2 Accuracy (Top-10 Same-Class)] {task2_acc:.4f}\")\n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "def plot_confusion_matrix(cm, class_names, title='Confusion Matrix', normalize=False):\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1, keepdims=True)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\".2f\" if normalize else \"d\", cmap=\"Blues\",\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(title)\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(img):\n",
    "    \"\"\"이미지 하나에 대해 여러 증강 중 하나를 랜덤 적용\"\"\"\n",
    "    choice = random.choice(['flip', 'rotate', 'brightness', 'blur', 'noise'])\n",
    "\n",
    "    if choice == 'flip':\n",
    "        return cv2.flip(img, 1)  # 좌우반전\n",
    "    elif choice == 'rotate':\n",
    "        angle = random.uniform(-15, 15)\n",
    "        h, w = img.shape[:2]\n",
    "        M = cv2.getRotationMatrix2D((w // 2, h // 2), angle, 1.0)\n",
    "        return cv2.warpAffine(img, M, (w, h), borderMode=cv2.BORDER_REFLECT)\n",
    "    elif choice == 'brightness':\n",
    "        factor = random.uniform(0.7, 1.3)\n",
    "        return np.clip(img.astype(np.float32) * factor, 0, 255).astype(np.uint8)\n",
    "    elif choice == 'blur':\n",
    "        return cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    elif choice == 'noise':\n",
    "        noise = np.random.normal(0, 10, img.shape).astype(np.uint8)\n",
    "        return cv2.add(img, noise)\n",
    "    return img  # fallback\n",
    "\n",
    "def augment_to_balance_min(df, target_min_per_class=500, seed=42):\n",
    "    \"\"\"클래스별로 최소 target 개수를 확보하도록 증강 (많은 클래스는 그대로 유지)\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    augmented_rows = []\n",
    "\n",
    "    for label, group in df.groupby('label'):\n",
    "        n_current = len(group)\n",
    "        n_needed = target_min_per_class - n_current\n",
    "\n",
    "        if n_needed <= 0:\n",
    "            print(f\"✅ {label}: {n_current}개 → 그대로 유지 (증강 없음)\")\n",
    "            augmented_rows.append(group)  # 그대로 사용 (잘라내지 않음!)\n",
    "        else:\n",
    "            print(f\"➕ {label}: {n_current}개 → {target_min_per_class}개로 증강 중 ({n_needed}개 생성)\")\n",
    "            samples_to_augment = group.sample(n=n_needed, replace=True, random_state=seed)\n",
    "\n",
    "            new_rows = []\n",
    "            for _, row in samples_to_augment.iterrows():\n",
    "                new_img = augment_image(row['image_data'])\n",
    "                new_rows.append({\n",
    "                    'label': row['label'],\n",
    "                    'image_data': new_img\n",
    "                })\n",
    "            augmented_rows.append(group)\n",
    "            augmented_rows.append(pd.DataFrame(new_rows))\n",
    "\n",
    "    balanced_df = pd.concat(augmented_rows).reset_index(drop=True)\n",
    "    return balanced_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "폴더 로드 중: 100%|██████████| 10/10 [00:06<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ 총 12700개의 이미지 로드 완료.\n",
      "✔ 라벨 인코딩 완료. 클래스: ['Bicycle' 'Bridge' 'Bus' 'Car' 'Chimney' 'Crosswalk' 'Hydrant'\n",
      " 'Motorcycle' 'Palm' 'Traffic Light']\n",
      "✅ Bicycle: 1299개 → 그대로 유지 (증강 없음)\n",
      "✅ Bridge: 553개 → 그대로 유지 (증강 없음)\n",
      "✅ Bus: 1500개 → 그대로 유지 (증강 없음)\n",
      "✅ Car: 1500개 → 그대로 유지 (증강 없음)\n",
      "➕ Chimney: 431개 → 500개로 증강 중 (69개 생성)\n",
      "✅ Crosswalk: 1260개 → 그대로 유지 (증강 없음)\n",
      "✅ Hydrant: 1032개 → 그대로 유지 (증강 없음)\n",
      "✅ Motorcycle: 681개 → 그대로 유지 (증강 없음)\n",
      "✅ Palm: 932개 → 그대로 유지 (증강 없음)\n",
      "✅ Traffic Light: 905개 → 그대로 유지 (증강 없음)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "C:\\Users\\bvb09\\AppData\\Local\\Temp\\ipykernel_8440\\2476747336.py:15: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  images_df = images_df.groupby('label').apply(\n"
     ]
    }
   ],
   "source": [
    "DATASET_BASE_PATH = \"C:/Users/bvb09/recaptcha-dataset\" \n",
    "\n",
    "try:\n",
    "    images_df = load_images_from_folder(DATASET_BASE_PATH)\n",
    "    print(f\"✔ 총 {len(images_df)}개의 이미지 로드 완료.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"오류: {e}\")\n",
    "    \n",
    "\n",
    "# 2. 라벨 인코딩\n",
    "le = LabelEncoder()\n",
    "images_df['label_encoded'] = le.fit_transform(images_df['label'])\n",
    "print(f\"✔ 라벨 인코딩 완료. 클래스: {le.classes_}\")\n",
    "\n",
    "images_df = images_df.groupby('label').apply(\n",
    "    lambda g: g.sample(n=1500, random_state=42) if g.name in ['Car', 'Bus'] else g\n",
    ").reset_index(drop=True)\n",
    "\n",
    "images_df = augment_to_balance_min(images_df)\n",
    "images_df['label_encoded'] = le.fit_transform(images_df['label'])\n",
    "\n",
    "# 전체 이미지 데이터에 대해 전처리 수행\n",
    "#print(\"⏳ 전체 이미지 전처리 중...\")\n",
    "#images_df['processed_image_data'] = [preprocess_image(img) for img in tqdm(images_df['image_data'], desc=\"이미지 전처리\")]\n",
    "#print(\"✔ 전체 이미지 전처리 완료.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ 기본 특징 추출 중 (Color, HOG, LBP, SIFT descriptors)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Color Histogram 추출: 100%|██████████| 10162/10162 [00:00<00:00, 17042.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# 전체 이미지 데이터에 대해 기본 특징 미리 추출\n",
    "print(\"⏳ 기본 특징 추출 중 (Color, HOG, LBP, SIFT descriptors)...\")\n",
    "features_color_all = np.array([extract_color_histogram_features(img) for img in tqdm(images_df['image_data'], desc=\"Color Histogram 추출\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LBP 추출: 100%|██████████| 10162/10162 [00:18<00:00, 551.49it/s]\n"
     ]
    }
   ],
   "source": [
    "features_lbp_all = np.array([extract_lbp_features_from_array(img) for img in tqdm(images_df['image_data'], desc=\"LBP 추출\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HOG 추출: 100%|██████████| 10162/10162 [00:14<00:00, 709.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10162, 1296)\n"
     ]
    }
   ],
   "source": [
    "hog_list = [\n",
    "    extract_hog_features(img)\n",
    "    for img in tqdm(images_df['image_data'], desc=\"HOG 추출\")\n",
    "]\n",
    "features_hog_all = np.vstack(hog_list)  # shape = (n_images, hog_dim)\n",
    "print(features_hog_all.shape)\n",
    "pca = PCA(n_components=50, random_state=42)\n",
    "features_hog_all = pca.fit_transform(features_hog_all)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#features_glcm_all = np.array([extract_glcm_features(img) for img in tqdm(images_df['image_data'], desc=\"GLCM 추출\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Laws' Texture 추출: 100%|██████████| 10162/10162 [01:00<00:00, 167.93it/s]\n"
     ]
    }
   ],
   "source": [
    "features_laws_all = np.array([extract_laws_energy_features(img) for img in tqdm(images_df['image_data'], desc=\"Laws' Texture 추출\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_reduce_descriptors(sift_descriptors_list_all, n_components=64):\n",
    "    \"\"\"\n",
    "    모든 이미지의 SIFT 디스크립터에 대해 PCA를 적용해 차원 축소.\n",
    "    PCA는 전체 디스크립터에서 1회 학습한 뒤, 각 디스크립터에 transform만 적용.\n",
    "    \"\"\"\n",
    "    # 유효한 디스크립터만 추출 (None 제거, 최소 차원 이상)\n",
    "    valid_descriptors = [d for d in sift_descriptors_list_all if d is not None and len(d) >= n_components]\n",
    "    \n",
    "    if len(valid_descriptors) == 0:\n",
    "        print(\"❌ PCA 학습할 디스크립터가 충분하지 않음. 차원 축소를 생략합니다.\")\n",
    "        return sift_descriptors_list_all\n",
    "\n",
    "    # 전체 디스크립터 결합\n",
    "    all_descriptors = np.vstack(valid_descriptors)\n",
    "\n",
    "    # PCA 학습\n",
    "    print(f\"🔍 PCA 학습 중... (입력 차원: {all_descriptors.shape[1]} → {n_components})\")\n",
    "    pca = PCA(n_components=n_components, random_state=42)\n",
    "    pca.fit(all_descriptors)\n",
    "\n",
    "    # 병렬 변환 함수\n",
    "    def transform_if_valid(desc):\n",
    "        if desc is None or len(desc) < n_components:\n",
    "            return desc\n",
    "        return pca.transform(desc)\n",
    "\n",
    "    # 병렬 적용\n",
    "    print(\"⚙ PCA 변환 병렬 적용 중...\")\n",
    "    reduced_descriptors = Parallel(n_jobs=6)(\n",
    "        delayed(transform_if_valid)(desc) for desc in sift_descriptors_list_all\n",
    "    )\n",
    "    \n",
    "    print(\"✅ PCA 축소 완료\")\n",
    "    return reduced_descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SIFT Descriptors 추출: 100%|██████████| 10162/10162 [01:39<00:00, 102.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 전체 이미지 수: 10162\n",
      "📊 PCA 학습에 사용된 디스크립터가 있는 이미지 수: 10162\n",
      "📊 PCA 학습에 사용된 전체 SIFT 벡터 수: 1756451\n"
     ]
    }
   ],
   "source": [
    "sift_descriptors_list_all = [extract_sift_descriptors_from_array(img) for img in tqdm(images_df['image_data'], desc=\"SIFT Descriptors 추출\")]\n",
    "\n",
    "# 전체 이미지 수\n",
    "total_count = len(sift_descriptors_list_all)\n",
    "\n",
    "# PCA 학습에 사용할 디스크립터만 필터링 (128차원인 경우만)\n",
    "all_descriptors = [des for des in sift_descriptors_list_all if des is not None and des.shape[1] == 128]\n",
    "pca_image_count = len(all_descriptors)  # 디스크립터가 존재하고 128차원인 이미지 수\n",
    "\n",
    "X_all = np.vstack(all_descriptors)\n",
    "\n",
    "# PCA 학습\n",
    "pca = PCA(n_components=64, random_state=42)\n",
    "pca.fit(X_all)\n",
    "\n",
    "print(f\"📊 전체 이미지 수: {total_count}\")\n",
    "print(f\"📊 PCA 학습에 사용된 디스크립터가 있는 이미지 수: {pca_image_count}\")\n",
    "print(f\"📊 PCA 학습에 사용된 전체 SIFT 벡터 수: {X_all.shape[0]}\")\n",
    "\n",
    "# PCA 변환 적용\n",
    "sift_descriptors_list_all = [\n",
    "    pca.transform(des) if des is not None and des.shape[1] == 128 else None\n",
    "    for des in sift_descriptors_list_all\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사용할 특징 조합 정의\n",
    "#feature_names = ['color', 'hog', 'lbp', 'sift']\n",
    "all_feature_combinations_tuples = []\n",
    "#from itertools import combinations\n",
    "#for i in range(1, len(feature_names) + 1):\n",
    "#    for combo in combinations(feature_names, i):\n",
    "#        all_feature_combinations_tuples.append(combo)\n",
    "\n",
    "# 사용자가 요청한 특정 조합 추가 (필요시)\n",
    "user_requested_combinations = [\n",
    " ('color', 'lbp'), ('color', 'lbp', 'hog'),\n",
    " ('color', 'law', 'hog'),\n",
    " ('color', 'lbp', 'sift', 'hog')\n",
    "]\n",
    "all_feature_combinations_tuples.extend(user_requested_combinations)\n",
    "# # 중복 제거\n",
    "# all_feature_combinations_tuples = sorted(list(set(all_feature_combinations_tuples)))\n",
    "\n",
    "\n",
    "print(f\"\\n▶ 총 {len(all_feature_combinations_tuples)}개의 특징 조합에 대해 교차 검증을 수행합니다.\")\n",
    "for combo in all_feature_combinations_tuples:\n",
    "    print(f\"  - {combo}\")\n",
    "\n",
    "# 결과를 저장할 딕셔너리\n",
    "results = {}\n",
    "confusion_matrices = {}\n",
    "\n",
    "X_indices = np.arange(len(images_df)) # StratifiedKFold에 사용할 인덱스\n",
    "y_labels = images_df['label_encoded'].values\n",
    "\n",
    "# Stratified K-Fold 준비\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42) # 노트북의 기본 5-fold 사용\n",
    "print(\"\\n✔ Stratified K-Fold 설정 완료 (5-Fold)\")\n",
    "\n",
    "# 교차 검증 루프\n",
    "num_bovw_clusters = 200 # BoVW 클러스터 수 (노트북의 get_features_for_split 함수 내 num_bovw_clusters=200 참고, 줄여서 테스트)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(X_indices, y_labels)):\n",
    "    print(f\"\\n=============== FOLD {fold+1}/5 ================\")\n",
    "    y_train_fold, y_val_fold = y_labels[train_idx], y_labels[val_idx]\n",
    "    # 현재 폴드의 SIFT 디스크립터 (훈련 데이터용, 검증 데이터용)\n",
    "    sift_descriptors_train_fold = [sift_descriptors_list_all[i] for i in train_idx]\n",
    "    sift_descriptors_val_fold = [sift_descriptors_list_all[i] for i in val_idx]\n",
    "\n",
    "    print(f\"  ⏳ BoVW Vocabulary 학습 중 (Fold {fold+1})\")\n",
    "    # SIFT 디스크립터가 하나도 없는 경우를 방지\n",
    "    valid_sift_descriptors_train_fold = [d for d in sift_descriptors_train_fold if d is not None and len(d) > 0]\n",
    "    bovw_vocabulary = learn_bovw_vocabulary(valid_sift_descriptors_train_fold, num_clusters=num_bovw_clusters)\n",
    "\n",
    "\n",
    "    # 각 특징 조합에 대해 학습 및 평가\n",
    "    for feature_combo_tuple in all_feature_combinations_tuples:\n",
    "        feature_combo_name = '+'.join(feature_combo_tuple)\n",
    "        print(f\"\\n--- 조합: {feature_combo_name} (Fold {fold+1}) ---\")\n",
    "        \n",
    "        X_train_features_list = []\n",
    "        X_val_features_list = []\n",
    "        \n",
    "        if 'color' in feature_combo_tuple:\n",
    "            X_train_features_list.append(features_color_all[train_idx])\n",
    "            X_val_features_list.append(features_color_all[val_idx])\n",
    "        if 'hog' in feature_combo_tuple:\n",
    "            X_train_features_list.append(features_hog_all[train_idx])\n",
    "            X_val_features_list.append(features_hog_all[val_idx])\n",
    "        if 'lbp' in feature_combo_tuple:\n",
    "            X_train_features_list.append(features_lbp_all[train_idx])\n",
    "            X_val_features_list.append(features_lbp_all[val_idx])\n",
    "        if 'laws' in feature_combo_tuple:\n",
    "            X_train_features_list.append(features_laws_all[train_idx])\n",
    "            X_val_features_list.append(features_laws_all[val_idx])    \n",
    "        if 'sift' in feature_combo_tuple:\n",
    "            if not valid_sift_descriptors_train_fold:\n",
    "                print(f\"  ⚠️ 경고: Fold {fold+1}의 훈련 데이터에 유효한 SIFT 디스크립터가 없어 BoVW 특징을 생성할 수 없습니다. 이 조합/폴드는 건너뜁니다.\")\n",
    "                # 빈 히스토그램 또는 오류 처리\n",
    "                num_features_sift = num_bovw_clusters \n",
    "                train_bovw_hist = np.zeros((len(train_idx), num_features_sift))\n",
    "                val_bovw_hist = np.zeros((len(val_idx), num_features_sift))\n",
    "            else:\n",
    "                if bovw_vocabulary is None or bovw_vocabulary.shape[0] == 0 :\n",
    "                     print(f\"  ⚠️ 경고: Fold {fold+1}에서 BoVW vocabulary 학습에 실패했습니다. 이 조합/폴드는 건너뜁니다.\")\n",
    "                     num_features_sift = num_bovw_clusters \n",
    "                     train_bovw_hist = np.zeros((len(train_idx), num_features_sift))\n",
    "                     val_bovw_hist = np.zeros((len(val_idx), num_features_sift))\n",
    "                else:\n",
    "                    print(f\"  ✔ BoVW Vocabulary 학습 완료 ({bovw_vocabulary.shape[0]} clusters).\")\n",
    "                    print(f\"  ⏳ BoVW Histogram 생성 중 (Fold {fold+1}, 조합 {feature_combo_name})...\")\n",
    "                    # 병렬 처리 + 벡터화된 히스토그램 생성\n",
    "                    train_bovw_hist = np.array(parallel_create_bovw_histograms(sift_descriptors_train_fold, bovw_vocabulary, n_jobs=-1))\n",
    "                    val_bovw_hist = np.array(parallel_create_bovw_histograms(sift_descriptors_val_fold, bovw_vocabulary, n_jobs=-1))\n",
    "\n",
    "            X_train_features_list.append(train_bovw_hist)\n",
    "            X_val_features_list.append(val_bovw_hist)\n",
    "\n",
    "        if not X_train_features_list: # 특징이 하나도 선택되지 않은 경우 (일어날 일 없지만 방어 코드)\n",
    "            print(f\"  ⚠️ 경고: 특징이 선택되지 않았습니다 ({feature_combo_name}). 건너뜁니다.\")\n",
    "            continue\n",
    "\n",
    "        # 특징 결합\n",
    "        X_train_combined = combine_features(*X_train_features_list)\n",
    "        X_val_combined = combine_features(*X_val_features_list)\n",
    "        \n",
    "        # 데이터 정규화 (필요시 추가 - 예: StandardScaler 또는 MinMaxScaler)\n",
    "        # scaler = StandardScaler()\n",
    "        # X_train_combined = scaler.fit_transform(X_train_combined)\n",
    "        # X_val_combined = scaler.transform(X_val_combined)\n",
    "        # print(\"  ℹ️ 특징 정규화 적용됨.\")\n",
    "\n",
    "        print(f\"  ⏳ Faiss KNN 모델 학습 중 (k=3, Fold {fold+1}, 조합 {feature_combo_name})...\")\n",
    "        # NaN 또는 Inf 값 확인 및 처리 (중요!)\n",
    "        if np.isnan(X_train_combined).any() or np.isinf(X_train_combined).any():\n",
    "            print(f\"  ⚠️ 경고: X_train_combined에 NaN 또는 Inf 값이 포함되어 있습니다. 0으로 대체합니다. (조합: {feature_combo_name}, Fold: {fold+1})\")\n",
    "            X_train_combined = np.nan_to_num(X_train_combined, nan=0.0, posinf=0.0, neginf=0.0) # 또는 다른 대체 전략\n",
    "        if np.isnan(X_val_combined).any() or np.isinf(X_val_combined).any():\n",
    "            print(f\"  ⚠️ 경고: X_val_combined에 NaN 또는 Inf 값이 포함되어 있습니다. 0으로 대체합니다. (조합: {feature_combo_name}, Fold: {fold+1})\")\n",
    "            X_val_combined = np.nan_to_num(X_val_combined, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        # 특징 벡터가 비어있거나 모든 값이 0인 경우를 처리 (L2 정규화 등에서 문제 발생 가능)\n",
    "        if X_train_combined.shape[1] == 0:\n",
    "            print(f\"  ⚠️ 경고: 훈련 특징 벡터가 비어있습니다. (조합: {feature_combo_name}, Fold: {fold+1}). 건너뜁니다.\")\n",
    "            continue\n",
    "        \n",
    "        # Faiss는 float32 타입을 요구함\n",
    "        X_train_combined = X_train_combined.astype(np.float32)\n",
    "        X_val_combined = X_val_combined.astype(np.float32)\n",
    "\n",
    "        try:\n",
    "            # train KNN\n",
    "            faiss_index, train_labels_for_pred, n_neighbors_actual = train_faiss_knn_euclidean(\n",
    "                X_train_combined, y_train_fold, n_neighbors=10\n",
    "            )\n",
    "    \n",
    "            print(f\"  ▶ KNN 예측 중 (Faiss 사용, k={n_neighbors_actual}, Fold {fold+1}, 조합 {feature_combo_name})...\")\n",
    "\n",
    "            # Top-k label list\n",
    "            y_pred_topk = predict_faiss_knn_euclidean_topk(\n",
    "                faiss_index, train_labels_for_pred, n_neighbors_actual, X_val_combined\n",
    "            )\n",
    "\n",
    "            # Top-1 predictions (가장 앞에 있는 것만 사용)\n",
    "            y_pred_fold = [row[0] for row in y_pred_topk]\n",
    "\n",
    "            # 기존 평가\n",
    "            acc = accuracy_score(y_val_fold, y_pred_fold)\n",
    "            fsc = f1_score(y_val_fold, y_pred_fold, average='weighted')\n",
    "\n",
    "            # ⬇️ Top-10 Accuracy 계산\n",
    "            top10_hits = [true in top10 for true, top10 in zip(y_val_fold, y_pred_topk)]\n",
    "            top10_acc = np.mean(top10_hits)\n",
    "\n",
    "            def task2_score(y_true, topk_preds, topk=10):\n",
    "                return np.mean([preds.count(t) / topk for t, preds in zip(y_true, topk_preds)])\n",
    "            task2 = task2_score(y_val_fold, y_pred_topk, topk=10)\n",
    "\n",
    "            print(f\"  ✔ 예측 완료.\")\n",
    "            print(f\"    ├ Top-1 Accuracy : {acc:.4f}\")\n",
    "            print(f\"    ├ Top-10 Accuracy: {top10_acc:.4f} (정답이 Top-10 안에 있으면 인정)\")\n",
    "            print(f\"    └ Task2 Score    : {task2:.4f} (Top-10 중 정답 등장 비율 평균)\")\n",
    "            print(f\"  ✔ F1-Score: {fsc:.4f} (Fold {fold+1}, 조합 {feature_combo_name})\")\n",
    "\n",
    "            # Confusion Matrix\n",
    "            cm = confusion_matrix(y_val_fold, y_pred_fold)\n",
    "            if feature_combo_name not in confusion_matrices:\n",
    "                confusion_matrices[feature_combo_name] = {}\n",
    "            confusion_matrices[feature_combo_name][fold] = cm\n",
    "\n",
    "            if feature_combo_name not in results:\n",
    "                results[feature_combo_name] = []\n",
    "            results[feature_combo_name].append(acc)\n",
    "\n",
    "            # 시각화\n",
    "            plot_confusion_matrix(\n",
    "                cm,\n",
    "                class_names=['Bicycle','Bridge','Bus', 'Car', 'Chimney','Crosswalk','Hydrant','Motorcycle','Palm','Traffic Light'],\n",
    "                title=f'{feature_combo_name} - Fold {fold+1}',\n",
    "                normalize=True\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"  ❌ 오류 발생 (Fold {fold+1}, 조합 {feature_combo_name}): {e}\")\n",
    "            if feature_combo_name not in results:\n",
    "                results[feature_combo_name] = []\n",
    "            results[feature_combo_name].append(np.nan)\n",
    "\n",
    "# 최종 결과 집계 및 출력\n",
    "print(\"\\n\\n=============== 최종 교차 검증 결과 ================\")\n",
    "for combo_name, acc_list in results.items():\n",
    "    valid_acc_list = [acc for acc in acc_list if not np.isnan(acc)]\n",
    "    if valid_acc_list:\n",
    "        mean_acc = np.mean(valid_acc_list)\n",
    "        std_acc = np.std(valid_acc_list)\n",
    "        print(f\"특징 조합: {combo_name}\")\n",
    "        for i, acc_fold in enumerate(acc_list):\n",
    "             print(f\"  Fold {i+1} Accuracy: {acc_fold:.4f}\" if not np.isnan(acc_fold) else f\"  Fold {i+1} Accuracy: Error\")\n",
    "        print(f\"  >> 평균 정확도: {mean_acc:.4f} (표준편차: {std_acc:.4f})\")\n",
    "    else:\n",
    "        print(f\"특징 조합: {combo_name} - 모든 폴드에서 오류 발생 또는 유효한 결과 없음.\")\n",
    "    print(\"-\" * 30)\n",
    "\n",
    "# 가장 성능이 좋은 조합 찾기 (평균 정확도 기준)\n",
    "if results:\n",
    "    sorted_results = sorted(results.items(), key=lambda item: np.nanmean(item[1]) if item[1] else -1, reverse=True)\n",
    "    print(\"\\n🏆 최고 성능 조합 (평균 정확도 기준):\")\n",
    "    if sorted_results and np.nanmean(sorted_results[0][1]):\n",
    "         best_combo_name, best_acc_list = sorted_results[0]\n",
    "         print(f\"  {best_combo_name}: 평균 정확도 = {np.nanmean(best_acc_list):.4f}\")\n",
    "    else:\n",
    "        print(\"  유효한 결과를 가진 조합이 없습니다.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
