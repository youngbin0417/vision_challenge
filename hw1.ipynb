{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bvb09\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/mikhailma/test-dataset?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393M/393M [00:15<00:00, 27.4MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\bvb09\\.cache\\kagglehub\\datasets\\mikhailma\\test-dataset\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"mikhailma/test-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 연산/데이터 처리\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 이미지 처리\n",
    "import cv2\n",
    "from skimage import color, exposure, filters, morphology, feature\n",
    "from skimage.util import img_as_ubyte\n",
    "\n",
    "# 특징 추출\n",
    "from skimage.feature import local_binary_pattern, hog\n",
    "from skimage.filters import gaussian, sobel, unsharp_mask\n",
    "from skimage.restoration import denoise_bilateral\n",
    "from skimage.morphology import disk, closing, opening\n",
    "from scipy import ndimage\n",
    "import mahotas\n",
    "\n",
    "\n",
    "# 머신러닝\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "\n",
    "# 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               image    label\n",
      "0  [[[104, 114, 117], [101, 110, 114], [100, 109,...  Bicycle\n",
      "1  [[[67, 75, 54], [69, 76, 58], [71, 77, 66], [6...  Bicycle\n",
      "2  [[[27, 33, 38], [28, 34, 37], [29, 34, 37], [3...  Bicycle\n",
      "3  [[[51, 49, 49], [58, 56, 55], [75, 73, 72], [9...  Bicycle\n",
      "4  [[[125, 128, 135], [129, 130, 143], [135, 135,...  Bicycle\n",
      "총 로드된 이미지 수: 11730\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "base_path = \"C:/Users/bvb09/.cache/kagglehub/datasets/mikhailma/test-dataset/versions/1/Google_Recaptcha_V2_Images_Dataset/images\"\n",
    "\n",
    "data = []\n",
    "\n",
    "# base_path 안에 있는 모든 하위 폴더 이름을 가져와 라벨로 지정\n",
    "label_folders = [f.name for f in os.scandir(base_path) if f.is_dir()]\n",
    "\n",
    "# 각 라벨 폴더를 순회합니다.\n",
    "for label in label_folders:\n",
    "    # 현재 라벨에 해당하는 폴더의 전체 경로를 만듭니다.\n",
    "    label_folder_path = os.path.join(base_path, label)\n",
    "    \n",
    "    # 해당 라벨 폴더 안의 모든 .png 이미지 파일 경로를 가져옵니다.\n",
    "    image_paths = glob.glob(os.path.join(label_folder_path, \"*.png\")) # 모든 이미지가 .png라고 가정합니다.\n",
    "\n",
    "    # 찾아낸 각 이미지 경로를 순회하며 이미지를 불러옵니다.\n",
    "    for fp in image_paths:\n",
    "        img = cv2.imread(fp)\n",
    "        if img is not None:  \n",
    "            img = cv2.resize(img, (120, 120)) \n",
    "            data.append((img, label)) # 이미지와 해당 폴더 이름을 라벨로 추가합니다.\n",
    "        else:\n",
    "            print(f\"경고: 이미지를 로드할 수 없습니다: {fp}\")\n",
    "\n",
    "# 리스트에 담긴 데이터를 Pandas DataFrame으로 변환합니다.\n",
    "df = pd.DataFrame(data, columns=[\"image\", \"label\"])\n",
    "\n",
    "# DataFrame의 처음 몇 줄을 출력하여 데이터를 확인합니다.\n",
    "print(df.head())\n",
    "print(f\"총 로드된 이미지 수: {len(df)}\")\n",
    "\n",
    "# 라벨 종류: bicycle, bridge, bus, car, chimney, crosswalk, hydrant, motorcycle, palm, stair, traffic light, other\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 0] ▶ Train: 9384개, Test: 2346개\n",
      "[Fold 1] ▶ Train: 9384개, Test: 2346개\n",
      "[Fold 2] ▶ Train: 9384개, Test: 2346개\n",
      "[Fold 3] ▶ Train: 9384개, Test: 2346개\n",
      "[Fold 4] ▶ Train: 9384개, Test: 2346개\n"
     ]
    }
   ],
   "source": [
    "# Stratified 5-fold cross validation\n",
    "\n",
    "# 이미지, 라벨 나누기\n",
    "X = np.array([img for img, _ in data])\n",
    "labels = [label for _, label in data]\n",
    "\n",
    "# 라벨 인코딩\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels)\n",
    "\n",
    "# Stratified K-Fold 준비\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# fold 저장용 리스트\n",
    "folds = []\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "    folds.append({\n",
    "        'fold': fold_idx,\n",
    "        'X_train': X[train_idx],\n",
    "        'y_train': y[train_idx],\n",
    "        'X_test': X[test_idx],\n",
    "        'y_test': y[test_idx]\n",
    "    })\n",
    "    \n",
    "    print(f\"[Fold {fold_idx}] ▶ Train: {len(train_idx)}개, Test: {len(test_idx)}개\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 라벨 분포: {np.int64(0): 156, np.int64(1): 107, np.int64(2): 242, np.int64(3): 711, np.int64(4): 25, np.int64(5): 248, np.int64(6): 191, np.int64(7): 16, np.int64(8): 268, np.int64(9): 182, np.int64(10): 42, np.int64(11): 158}\n",
      "Fold 1 라벨 분포: {np.int64(0): 156, np.int64(1): 107, np.int64(2): 242, np.int64(3): 711, np.int64(4): 25, np.int64(5): 248, np.int64(6): 190, np.int64(7): 17, np.int64(8): 268, np.int64(9): 182, np.int64(10): 42, np.int64(11): 158}\n",
      "Fold 2 라벨 분포: {np.int64(0): 156, np.int64(1): 107, np.int64(2): 241, np.int64(3): 712, np.int64(4): 25, np.int64(5): 248, np.int64(6): 190, np.int64(7): 16, np.int64(8): 268, np.int64(9): 183, np.int64(10): 42, np.int64(11): 158}\n",
      "Fold 3 라벨 분포: {np.int64(0): 156, np.int64(1): 106, np.int64(2): 242, np.int64(3): 712, np.int64(4): 25, np.int64(5): 248, np.int64(6): 190, np.int64(7): 16, np.int64(8): 268, np.int64(9): 182, np.int64(10): 43, np.int64(11): 158}\n",
      "Fold 4 라벨 분포: {np.int64(0): 156, np.int64(1): 106, np.int64(2): 242, np.int64(3): 712, np.int64(4): 24, np.int64(5): 248, np.int64(6): 191, np.int64(7): 16, np.int64(8): 268, np.int64(9): 182, np.int64(10): 42, np.int64(11): 159}\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "for f in folds:\n",
    "    counter = collections.Counter(f['y_test'])\n",
    "    print(f\"Fold {f['fold']} 라벨 분포: {dict(counter)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing (image enhancement)\n",
    "\n",
    "# Point Processing\n",
    "def contrast_stretch(image):\n",
    "    # 2% ~ 98% 범위로 contrast stretching\n",
    "    p2, p98 = np.percentile(image, (2, 98))\n",
    "    return exposure.rescale_intensity(image, in_range=(p2, p98))\n",
    "\n",
    "# Gray scale / HSI 변환\n",
    "def to_grayscale(image):\n",
    "    if len(image.shape) == 3:\n",
    "        return color.rgb2gray(image)\n",
    "    else:\n",
    "        print(\"hsi 변형 불가능\")\n",
    "        return image\n",
    "\n",
    "def to_hsi(image):\n",
    "    hsv = color.rgb2hsv(image)\n",
    "    return hsv[:, :, 0], hsv[:, :, 1], hsv[:, :, 2]  # hue, sat, intensity\n",
    "\n",
    "# Histogram Equalization (area processing)\n",
    "def histogram_equalization(image):\n",
    "    return exposure.equalize_hist(image)\n",
    "\n",
    "# Noise Filtering \n",
    "def remove_noise(image):\n",
    "    image = gaussian(image, sigma=1)\n",
    "    return denoise_bilateral(image, sigma_color=0.05, sigma_spatial=15, channel_axis=None)\n",
    "\n",
    "# Morphological Operators \n",
    "def morphological_close(image_binary, selem_size=3):\n",
    "    selem = disk(selem_size)\n",
    "    return morphology.closing(image_binary, selem)\n",
    "\n",
    "def morphological_open(image_binary, selem_size=3):\n",
    "    selem = disk(selem_size)\n",
    "    return morphology.opening(image_binary, selem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge Feature\n",
    "\n",
    "# Edge Detection \n",
    "def sobel_detection(image_gray):\n",
    "    return sobel(image_gray)\n",
    "\n",
    "def edge_detection(image_gray, low_threshold=50, high_threshold=150, aperture_size=3):\n",
    "    # 1) float나 다른 타입이라면 0~255 스케일 후 uint8 로 변환\n",
    "    if image_gray.dtype != np.uint8:\n",
    "        # 영상이 0~1 사이의 float라면 255 곱해주고, 아니면 절댓값 후 변환\n",
    "        image_gray = cv2.convertScaleAbs(image_gray)\n",
    "    # 2) 캐니 엣지\n",
    "    return cv2.Canny(image_gray, low_threshold, high_threshold, apertureSize=aperture_size)\n",
    "\n",
    "# Sharpening: Unsharp Mask 대신 Canny 엣지로 마스크 생성 후 강조\n",
    "def sharpen_image(image_gray, low_threshold=50, high_threshold=150, amount=1.0):\n",
    "    # 1) Canny 엣지 맵\n",
    "    edges = cv2.Canny(image_gray, low_threshold, high_threshold)\n",
    "    # 2) 엣지를 mask로 사용해 원본에 더함\n",
    "    #    edges는 0/255 이므로 255로 나눈 뒤 float 연산\n",
    "    mask = (edges / 255.0).astype(np.float32)\n",
    "    sharpened = image_gray.astype(np.float32) + amount * (mask * 255.0)\n",
    "    # 3) uint8로 클리핑 후 반환\n",
    "    return np.clip(sharpened, 0, 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color Feature\n",
    "\n",
    "def extract_color_features(image):\n",
    "    # RGB 히스토그램\n",
    "    hist_r = cv2.calcHist([image], [0], None, [32], [0, 256])\n",
    "    hist_g = cv2.calcHist([image], [1], None, [32], [0, 256])\n",
    "    hist_b = cv2.calcHist([image], [2], None, [32], [0, 256])\n",
    "    \n",
    "    # HSV 변환 및 히스토그램\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist_h = cv2.calcHist([hsv], [0], None, [32], [0, 180])\n",
    "    hist_s = cv2.calcHist([hsv], [1], None, [32], [0, 256])\n",
    "    hist_v = cv2.calcHist([hsv], [2], None, [32], [0, 256])\n",
    "    \n",
    "    # 정규화\n",
    "    features = np.concatenate([\n",
    "        hist_r.flatten(), hist_g.flatten(), hist_b.flatten(),\n",
    "        hist_h.flatten(), hist_s.flatten(), hist_v.flatten()\n",
    "    ])\n",
    "    return features / np.sum(features)  # 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texture Feature\n",
    "\n",
    "# LBP 함수\n",
    "def extract_lbp_features(image_gray, radius=1, method='uniform'):\n",
    "    n_points = 8 * radius\n",
    "    lbp = feature.local_binary_pattern(image_gray, n_points, radius, method)\n",
    "    n_bins = int(lbp.max() + 1)\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins), density=True)\n",
    "    return hist\n",
    "\n",
    "# Laws' Texture Energy 함수\n",
    "def extract_laws_energy_features(image_gray, window_size=15):\n",
    "    # 1D Laws kernels\n",
    "    L5 = np.array([1, 4, 6, 4, 1], dtype=np.float32)\n",
    "    E5 = np.array([-1, -2,  0,  2,  1], dtype=np.float32)\n",
    "    S5 = np.array([-1,  0,  2,  0, -1], dtype=np.float32)\n",
    "    W5 = np.array([-1,  2,  0, -2,  1], dtype=np.float32)\n",
    "    R5 = np.array([1, -4,  6, -4,  1], dtype=np.float32)\n",
    "    kernels = [L5, E5, S5, W5, R5]\n",
    "\n",
    "    energy_features = []\n",
    "    for k1 in kernels:\n",
    "        for k2 in kernels:\n",
    "            # build 2D Laws kernel\n",
    "            kernel = np.outer(k1, k2)\n",
    "            # convolve and take absolute value (energy)\n",
    "            filtered = ndimage.convolve(image_gray.astype(np.float32),\n",
    "                                        kernel, mode='reflect')\n",
    "            energy = np.abs(filtered)\n",
    "            # sum local energy with a box filter\n",
    "            summed = cv2.boxFilter(energy, ddepth=-1,\n",
    "                                   ksize=(window_size, window_size),\n",
    "                                   normalize=False)\n",
    "            # global average energy for this filter\n",
    "            energy_features.append(summed.mean())\n",
    "\n",
    "    return np.array(energy_features, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape Feature\n",
    "\n",
    "def extract_sift_descriptors(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "\n",
    "    return descriptors\n",
    "\n",
    "def extract_hog_descriptors(image):\n",
    "    features = hog(\n",
    "        image,\n",
    "        orientations=9,\n",
    "        pixels_per_cell=(8, 8),\n",
    "        cells_per_block=(2, 2),\n",
    "        block_norm='L2-Hys',\n",
    "        transform_sqrt=True,\n",
    "        feature_vector=True\n",
    "    )\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_image(img, sigma=1.0):\n",
    "    img = contrast_stretch(img)\n",
    "    img = to_grayscale(img)\n",
    "    img = histogram_equalization(img)\n",
    "    img = remove_noise(img)\n",
    "    img = edge_detection(img)\n",
    "    img = cv2.convertScaleAbs(img)\n",
    "    img = sharpen_image(img)\n",
    "    return img\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature 함수\n",
    "def extract_features(img):\n",
    "    \"\"\"\n",
    "    img: 2D np.uint8 grayscale image\n",
    "    returns: L2-normalized 1D feature vector combining LBP, HOG, SIFT, and Laws energy.\n",
    "    \"\"\"\n",
    "    # 1) 입력이 이미 그레이스케일이라 가정, uint8 보장\n",
    "    gray = img.astype(np.uint8)\n",
    "\n",
    "    # 2) 개별 피처 추출\n",
    "    lbp_vec  = extract_lbp_features(gray, radius=1, method='uniform')\n",
    "    hog_vec  = extract_hog_descriptors(gray)\n",
    "    desc     = extract_sift_descriptors(gray)  # 반드시 uint8\n",
    "    if desc is not None and len(desc) > 0:\n",
    "        sift_vec = desc.mean(axis=0).astype(np.float32)  # 128D\n",
    "    else:\n",
    "        sift_vec = np.zeros(128, dtype=np.float32)\n",
    "    laws_vec = extract_laws_energy_features(gray, window_size=15)\n",
    "\n",
    "    # 3) 그룹별 정규화\n",
    "    norm = np.linalg.norm(lbp_vec, ord=1)\n",
    "    if norm > 0: lbp_vec /= norm\n",
    "\n",
    "    norm = np.linalg.norm(hog_vec, ord=2)\n",
    "    if norm > 0: hog_vec /= norm\n",
    "\n",
    "    norm = np.linalg.norm(sift_vec, ord=2)\n",
    "    if norm > 0: sift_vec /= norm\n",
    "\n",
    "    norm = np.linalg.norm(laws_vec, ord=2)\n",
    "    if norm > 0: laws_vec /= norm\n",
    "\n",
    "    # 4) 최종 벡터 합치고 전체 L2 정규화\n",
    "    feat = np.concatenate([lbp_vec, hog_vec, sift_vec, laws_vec]).astype(np.float32)\n",
    "    norm = np.linalg.norm(feat, ord=2)\n",
    "    if norm > 0:\n",
    "        feat /= norm\n",
    "\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-means clustering\n",
    "def kmeans_clustering(features, n_clusters=10):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(features)\n",
    "    return kmeans, cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier (knn)\n",
    "\n",
    "def chi2_distance(x, y):\n",
    "    \"\"\"\n",
    "    Chi-square distance for histogram features.\n",
    "    Returns 0.5 * sum((x - y)^2 / (x + y + eps)).\n",
    "    \"\"\"\n",
    "    eps = 1e-10\n",
    "    return 0.5 * np.sum((x - y) ** 2 / (x + y + eps))\n",
    "\n",
    "def train_knn_classifier(features, labels, n_neighbors=5, weights='distance', metric='chi2'):\n",
    "    if metric == 'chi2':\n",
    "        metric_fn = chi2_distance\n",
    "    else:\n",
    "        metric_fn = metric  # can be 'euclidean', 'cosine', or a callable\n",
    "\n",
    "    knn = KNeighborsClassifier(\n",
    "        n_neighbors=n_neighbors,\n",
    "        weights=weights,\n",
    "        metric=metric_fn\n",
    "    )\n",
    "    knn.fit(features, labels)\n",
    "    return knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "def test(model, X_test, y_test, average='weighted'): # <- average 파라미터 추가\n",
    "    \"\"\"\n",
    "    model: train()이 반환한 KNeighborsClassifier\n",
    "    X_test: train()이 반환한 테스트 feature 벡터\n",
    "    y_test: train()이 반환한 테스트 라벨\n",
    "    Prints:\n",
    "        - 전체 정확도\n",
    "        - 각 클래스별 리포트\n",
    "    Returns:\n",
    "        y_pred: 예측된 라벨 배열\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    # average 파라미터를 precision_score와 recall_score에 전달\n",
    "    prec = precision_score(y_test, y_pred, average=average, zero_division=0)\n",
    "    rec  = recall_score(y_test, y_pred, average=average, zero_division=0)\n",
    "    print(f\"[Test Accuracy] {acc:.4f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 0 ===\n",
      "  ▶ Train feature extraction (Fold 0)...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[35]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  ▶ Train feature extraction (Fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf[\u001b[33m'\u001b[39m\u001b[33mfold\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# n_jobs=-1 은 사용 가능한 모든 CPU 코어를 사용하겠다는 의미입니다.\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m X_train_feats = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreprocess_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mX_train\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m X_train_feats = np.array(X_train_feats) \u001b[38;5;66;03m# 리스트를 numpy 배열로 변환\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  ✔ Train feature extraction complete for Fold \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf[\u001b[33m'\u001b[39m\u001b[33mfold\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bvb09\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:2071\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2065\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2066\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2067\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2068\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2069\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2071\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bvb09\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1681\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1678\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1680\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1681\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1683\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1684\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1685\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1686\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1687\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\bvb09\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1799\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1788\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_ordered:\n\u001b[32m   1789\u001b[39m     \u001b[38;5;66;03m# Case ordered: wait for completion (or error) of the next job\u001b[39;00m\n\u001b[32m   1790\u001b[39m     \u001b[38;5;66;03m# that have been dispatched and not retrieved yet. If no job\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1794\u001b[39m     \u001b[38;5;66;03m# control only have to be done on the amount of time the next\u001b[39;00m\n\u001b[32m   1795\u001b[39m     \u001b[38;5;66;03m# dispatched job is pending.\u001b[39;00m\n\u001b[32m   1796\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (nb_jobs == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1797\u001b[39m         \u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING\n\u001b[32m   1798\u001b[39m     ):\n\u001b[32m-> \u001b[39m\u001b[32m1799\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1800\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1802\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m nb_jobs == \u001b[32m0\u001b[39m:\n\u001b[32m   1803\u001b[39m     \u001b[38;5;66;03m# Case unordered: jobs are added to the list of jobs to\u001b[39;00m\n\u001b[32m   1804\u001b[39m     \u001b[38;5;66;03m# retrieve `self._jobs` only once completed or in error, which\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1810\u001b[39m     \u001b[38;5;66;03m# timeouts before any other dispatched job has completed and\u001b[39;00m\n\u001b[32m   1811\u001b[39m     \u001b[38;5;66;03m# been added to `self._jobs` to be retrieved.\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 결과 저장용\n",
    "accuracies = []\n",
    "precisions = []\n",
    "recalls = []\n",
    "\n",
    "for f in folds:\n",
    "    print(f\"\\n=== Fold {f['fold']} ===\")\n",
    "\n",
    "    # 1) train set에서 feature 추출 & 학습 (병렬 처리 적용)\n",
    "    print(f\"  ▶ Train feature extraction (Fold {f['fold']})...\")\n",
    "    # n_jobs=-1 은 사용 가능한 모든 CPU 코어를 사용하겠다는 의미입니다.\n",
    "    X_train_feats = Parallel(n_jobs=-1)(\n",
    "        delayed(lambda img: extract_features(preprocess_image(img)))(img)\n",
    "        for img in f['X_train']\n",
    "    )\n",
    "    X_train_feats = np.array(X_train_feats) # 리스트를 numpy 배열로 변환\n",
    "    print(f\"  ✔ Train feature extraction complete for Fold {f['fold']}.\")\n",
    "\n",
    "    knn = train_knn_classifier(\n",
    "        X_train_feats, # 이미 numpy 배열입니다.\n",
    "        f['y_train'],\n",
    "        n_neighbors=5\n",
    "    )\n",
    "\n",
    "    # 2) test set에서 feature 추출 & 평가 (병렬 처리 적용)\n",
    "    print(f\"  ▶ Test feature extraction (Fold {f['fold']})...\")\n",
    "    X_test_feats = Parallel(n_jobs=-1)(\n",
    "        delayed(lambda img: extract_features(preprocess_image(img)))(img)\n",
    "        for img in f['X_test']\n",
    "    )\n",
    "    X_test_feats = np.array(X_test_feats) # 리스트를 numpy 배열로 변환\n",
    "    print(f\"  ✔ Test feature extraction complete for Fold {f['fold']}.\")\n",
    "\n",
    "\n",
    "    # test() 함수는 precision/recall/accuracy와 classification report를 출력하고,\n",
    "    # y_pred를 리턴합니다.\n",
    "    y_pred = test(\n",
    "        knn,\n",
    "        X_test_feats, # 이미 numpy 배열입니다.\n",
    "        f['y_test'],\n",
    "        average='weighted'\n",
    "    )\n",
    "\n",
    "    # 3) 필요하면 fold별 지표를 저장\n",
    "    # (test() 내부에서 이미 print 되지만, 나중에 평균 낼 때를 위해)\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "    acc  = accuracy_score(f['y_test'], y_pred)\n",
    "    prec = precision_score(f['y_test'], y_pred, average='weighted', zero_division=0)\n",
    "    rec  = recall_score(f['y_test'], y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "    accuracies.append(acc)\n",
    "    precisions.append(prec)\n",
    "    recalls.append(rec)\n",
    "\n",
    "# 4) 5-fold 평균 지표 출력\n",
    "print(\"\\n=== 5-Fold CV Average ===\")\n",
    "print(f\"Accuracy : {np.mean(accuracies):.4f} ± {np.std(accuracies):.4f}\")\n",
    "print(f\"Precision: {np.mean(precisions):.4f} ± {np.std(precisions):.4f}\")\n",
    "print(f\"Recall   : {np.mean(recalls):.4f} ± {np.std(recalls):.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
