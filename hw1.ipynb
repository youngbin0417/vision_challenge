{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bvb09\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/mikhailma/test-dataset?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393M/393M [00:15<00:00, 27.4MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\bvb09\\.cache\\kagglehub\\datasets\\mikhailma\\test-dataset\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"mikhailma/test-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 연산/데이터 처리\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 이미지 처리\n",
    "import cv2\n",
    "from skimage import color, exposure, filters, morphology, feature\n",
    "from skimage.util import img_as_ubyte\n",
    "\n",
    "# 특징 추출\n",
    "from skimage.feature import local_binary_pattern, hog\n",
    "from skimage.filters import gaussian, sobel, unsharp_mask\n",
    "from skimage.restoration import denoise_bilateral\n",
    "from skimage.morphology import disk, closing, opening\n",
    "import mahotas\n",
    "\n",
    "\n",
    "# 머신러닝\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SIFT (OpenCV contrib 필요)\n",
    "sift = cv2.SIFT_create()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               image    label\n",
      "0  [[[104, 114, 117], [103, 112, 116], [101, 110,...  Bicycle\n",
      "1  [[[67, 75, 54], [68, 75, 55], [69, 76, 58], [7...  Bicycle\n",
      "2  [[[27, 33, 38], [27, 33, 38], [28, 34, 37], [2...  Bicycle\n",
      "3  [[[51, 49, 49], [54, 52, 51], [58, 56, 55], [6...  Bicycle\n",
      "4  [[[125, 128, 135], [127, 129, 138], [129, 130,...  Bicycle\n",
      "총 로드된 이미지 수: 11730\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "base_path = \"C:/Users/bvb09/.cache/kagglehub/datasets/mikhailma/test-dataset/versions/1/Google_Recaptcha_V2_Images_Dataset/images\"\n",
    "\n",
    "data = []\n",
    "\n",
    "# base_path 안에 있는 모든 하위 폴더 이름을 가져와 라벨로 지정\n",
    "label_folders = [f.name for f in os.scandir(base_path) if f.is_dir()]\n",
    "\n",
    "# 각 라벨 폴더를 순회합니다.\n",
    "for label in label_folders:\n",
    "    # 현재 라벨에 해당하는 폴더의 전체 경로를 만듭니다.\n",
    "    label_folder_path = os.path.join(base_path, label)\n",
    "    \n",
    "    # 해당 라벨 폴더 안의 모든 .png 이미지 파일 경로를 가져옵니다.\n",
    "    image_paths = glob.glob(os.path.join(label_folder_path, \"*.png\")) # 모든 이미지가 .png라고 가정합니다.\n",
    "\n",
    "    # 찾아낸 각 이미지 경로를 순회하며 이미지를 불러옵니다.\n",
    "    for fp in image_paths:\n",
    "        img = cv2.imread(fp)\n",
    "        if img is not None:  \n",
    "            img = cv2.resize(img, (200, 200)) \n",
    "            data.append((img, label)) # 이미지와 해당 폴더 이름을 라벨로 추가합니다.\n",
    "        else:\n",
    "            print(f\"경고: 이미지를 로드할 수 없습니다: {fp}\")\n",
    "\n",
    "# 리스트에 담긴 데이터를 Pandas DataFrame으로 변환합니다.\n",
    "df = pd.DataFrame(data, columns=[\"image\", \"label\"])\n",
    "\n",
    "# DataFrame의 처음 몇 줄을 출력하여 데이터를 확인합니다.\n",
    "print(df.head())\n",
    "print(f\"총 로드된 이미지 수: {len(df)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 0] ▶ Train: 9384개, Test: 2346개\n",
      "[Fold 1] ▶ Train: 9384개, Test: 2346개\n",
      "[Fold 2] ▶ Train: 9384개, Test: 2346개\n",
      "[Fold 3] ▶ Train: 9384개, Test: 2346개\n",
      "[Fold 4] ▶ Train: 9384개, Test: 2346개\n"
     ]
    }
   ],
   "source": [
    "# Stratified 5-fold cross validation\n",
    "\n",
    "# 이미지, 라벨 나누기\n",
    "X = np.array([img for img, _ in data])\n",
    "labels = [label for _, label in data]\n",
    "\n",
    "# 라벨 인코딩\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels)\n",
    "\n",
    "# Stratified K-Fold 준비\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# fold 저장용 리스트\n",
    "folds = []\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "    folds.append({\n",
    "        'fold': fold_idx,\n",
    "        'X_train': X[train_idx],\n",
    "        'y_train': y[train_idx],\n",
    "        'X_test': X[test_idx],\n",
    "        'y_test': y[test_idx]\n",
    "    })\n",
    "    \n",
    "    print(f\"[Fold {fold_idx}] ▶ Train: {len(train_idx)}개, Test: {len(test_idx)}개\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 라벨 분포: {np.int64(0): 156, np.int64(1): 107, np.int64(2): 242, np.int64(3): 711, np.int64(4): 25, np.int64(5): 248, np.int64(6): 191, np.int64(7): 16, np.int64(8): 268, np.int64(9): 182, np.int64(10): 42, np.int64(11): 158}\n",
      "Fold 1 라벨 분포: {np.int64(0): 156, np.int64(1): 107, np.int64(2): 242, np.int64(3): 711, np.int64(4): 25, np.int64(5): 248, np.int64(6): 190, np.int64(7): 17, np.int64(8): 268, np.int64(9): 182, np.int64(10): 42, np.int64(11): 158}\n",
      "Fold 2 라벨 분포: {np.int64(0): 156, np.int64(1): 107, np.int64(2): 241, np.int64(3): 712, np.int64(4): 25, np.int64(5): 248, np.int64(6): 190, np.int64(7): 16, np.int64(8): 268, np.int64(9): 183, np.int64(10): 42, np.int64(11): 158}\n",
      "Fold 3 라벨 분포: {np.int64(0): 156, np.int64(1): 106, np.int64(2): 242, np.int64(3): 712, np.int64(4): 25, np.int64(5): 248, np.int64(6): 190, np.int64(7): 16, np.int64(8): 268, np.int64(9): 182, np.int64(10): 43, np.int64(11): 158}\n",
      "Fold 4 라벨 분포: {np.int64(0): 156, np.int64(1): 106, np.int64(2): 242, np.int64(3): 712, np.int64(4): 24, np.int64(5): 248, np.int64(6): 191, np.int64(7): 16, np.int64(8): 268, np.int64(9): 182, np.int64(10): 42, np.int64(11): 159}\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "for f in folds:\n",
    "    counter = collections.Counter(f['y_test'])\n",
    "    print(f\"Fold {f['fold']} 라벨 분포: {dict(counter)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "\n",
    "# Point Processing\n",
    "def contrast_stretch(image):\n",
    "    # 2% ~ 98% 범위로 contrast stretching\n",
    "    p2, p98 = np.percentile(image, (2, 98))\n",
    "    return exposure.rescale_intensity(image, in_range=(p2, p98))\n",
    "\n",
    "# Gray scale / HSI 변환\n",
    "def to_grayscale(image):\n",
    "    return color.rgb2gray(image)\n",
    "\n",
    "def to_hsi(image):\n",
    "    hsv = color.rgb2hsv(image)\n",
    "    return hsv[:, :, 0], hsv[:, :, 1], hsv[:, :, 2]  # hue, sat, intensity\n",
    "\n",
    "# Histogram Equalization (area processing)\n",
    "def histogram_equalization(image):\n",
    "    return exposure.equalize_hist(image)\n",
    "\n",
    "# Noise Filtering \n",
    "def remove_noise(image):\n",
    "    image = gaussian(image, sigma=1)\n",
    "    return denoise_bilateral(image, sigma_color=0.05, sigma_spatial=15, channel_axis=None)\n",
    "\n",
    "# Edge Detection \n",
    "def edge_detection(image_gray):\n",
    "    return sobel(image_gray)\n",
    "\n",
    "# Sharpening \n",
    "def sharpen_image(image_gray):\n",
    "    return unsharp_mask(image_gray, radius=1, amount=1)\n",
    "\n",
    "# Morphological Operators \n",
    "def morphological_close(image_binary, selem_size=3):\n",
    "    selem = disk(selem_size)\n",
    "    return morphology.closing(image_binary, selem)\n",
    "\n",
    "def morphological_open(image_binary, selem_size=3):\n",
    "    selem = disk(selem_size)\n",
    "    return morphology.opening(image_binary, selem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LBP feature 추출 함수\n",
    "def extract_lbp_features(image_gray, radius=1, method='uniform'):\n",
    "    n_points = 8 * radius\n",
    "    lbp = feature.local_binary_pattern(image_gray, n_points, radius, method)\n",
    "    n_bins = int(lbp.max() + 1)\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins), density=True)\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_image(img, sigma=1.0):\n",
    "    img = contrast_stretch(img)\n",
    "    img = to_grayscale(img)\n",
    "    img = histogram_equalization(img)\n",
    "    img = remove_noise(img)\n",
    "    img = edge_detection(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# texture 함수\n",
    "def texture_features(img):\n",
    "    return extract_lbp_features(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape 함수"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
