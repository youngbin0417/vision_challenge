{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bvb09\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/mikhailma/test-dataset?dataset_version_number=1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 393M/393M [00:15<00:00, 27.4MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\bvb09\\.cache\\kagglehub\\datasets\\mikhailma\\test-dataset\\versions\\1\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "# Download latest version\n",
    "path = kagglehub.dataset_download(\"mikhailma/test-dataset\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 연산/데이터 처리\n",
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 이미지 처리\n",
    "import cv2\n",
    "from skimage import color, exposure, filters, morphology, feature\n",
    "from skimage.util import img_as_ubyte\n",
    "\n",
    "# 특징 추출\n",
    "from skimage.feature import local_binary_pattern, hog\n",
    "from skimage.filters import gaussian, sobel, unsharp_mask\n",
    "from skimage.restoration import denoise_bilateral\n",
    "from skimage.morphology import disk, closing, opening\n",
    "from scipy import ndimage\n",
    "import mahotas\n",
    "\n",
    "\n",
    "# 머신러닝\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "\n",
    "# 시각화\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               image    label\n",
      "0  [[[104, 114, 117], [101, 110, 114], [100, 109,...  Bicycle\n",
      "1  [[[67, 75, 54], [69, 76, 58], [71, 77, 66], [6...  Bicycle\n",
      "2  [[[27, 33, 38], [28, 34, 37], [29, 34, 37], [3...  Bicycle\n",
      "3  [[[51, 49, 49], [58, 56, 55], [75, 73, 72], [9...  Bicycle\n",
      "4  [[[125, 128, 135], [129, 130, 143], [135, 135,...  Bicycle\n",
      "총 로드된 이미지 수: 11730\n"
     ]
    }
   ],
   "source": [
    "# 데이터 로드\n",
    "base_path = \"C:/Users/bvb09/.cache/kagglehub/datasets/mikhailma/test-dataset/versions/1/Google_Recaptcha_V2_Images_Dataset/images\"\n",
    "\n",
    "data = []\n",
    "\n",
    "# base_path 안에 있는 모든 하위 폴더 이름을 가져와 라벨로 지정\n",
    "label_folders = [f.name for f in os.scandir(base_path) if f.is_dir()]\n",
    "\n",
    "# 각 라벨 폴더를 순회합니다.\n",
    "for label in label_folders:\n",
    "    # 현재 라벨에 해당하는 폴더의 전체 경로를 만듭니다.\n",
    "    label_folder_path = os.path.join(base_path, label)\n",
    "    \n",
    "    # 해당 라벨 폴더 안의 모든 .png 이미지 파일 경로를 가져옵니다.\n",
    "    image_paths = glob.glob(os.path.join(label_folder_path, \"*.png\")) # 모든 이미지가 .png라고 가정합니다.\n",
    "\n",
    "    # 찾아낸 각 이미지 경로를 순회하며 이미지를 불러옵니다.\n",
    "    for fp in image_paths:\n",
    "        img = cv2.imread(fp)\n",
    "        if img is not None:  \n",
    "            img = cv2.resize(img, (120, 120)) \n",
    "            data.append((img, label)) # 이미지와 해당 폴더 이름을 라벨로 추가합니다.\n",
    "        else:\n",
    "            print(f\"경고: 이미지를 로드할 수 없습니다: {fp}\")\n",
    "\n",
    "# 리스트에 담긴 데이터를 Pandas DataFrame으로 변환합니다.\n",
    "df = pd.DataFrame(data, columns=[\"image\", \"label\"])\n",
    "\n",
    "# DataFrame의 처음 몇 줄을 출력하여 데이터를 확인합니다.\n",
    "print(df.head())\n",
    "print(f\"총 로드된 이미지 수: {len(df)}\")\n",
    "\n",
    "# 라벨 종류: bicycle, bridge, bus, car, chimney, crosswalk, hydrant, motorcycle, palm, stair, traffic light, other\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Fold 0] ▶ Train: 9384개, Test: 2346개\n",
      "[Fold 1] ▶ Train: 9384개, Test: 2346개\n",
      "[Fold 2] ▶ Train: 9384개, Test: 2346개\n",
      "[Fold 3] ▶ Train: 9384개, Test: 2346개\n",
      "[Fold 4] ▶ Train: 9384개, Test: 2346개\n"
     ]
    }
   ],
   "source": [
    "# Stratified 5-fold cross validation\n",
    "\n",
    "# 이미지, 라벨 나누기\n",
    "X = np.array([img for img, _ in data])\n",
    "labels = [label for _, label in data]\n",
    "\n",
    "# 라벨 인코딩\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(labels)\n",
    "\n",
    "# Stratified K-Fold 준비\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# fold 저장용 리스트\n",
    "folds = []\n",
    "\n",
    "for fold_idx, (train_idx, test_idx) in enumerate(skf.split(X, y)):\n",
    "    folds.append({\n",
    "        'fold': fold_idx,\n",
    "        'X_train': X[train_idx],\n",
    "        'y_train': y[train_idx],\n",
    "        'X_test': X[test_idx],\n",
    "        'y_test': y[test_idx]\n",
    "    })\n",
    "    \n",
    "    print(f\"[Fold {fold_idx}] ▶ Train: {len(train_idx)}개, Test: {len(test_idx)}개\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0 라벨 분포: {np.int64(0): 156, np.int64(1): 107, np.int64(2): 242, np.int64(3): 711, np.int64(4): 25, np.int64(5): 248, np.int64(6): 191, np.int64(7): 16, np.int64(8): 268, np.int64(9): 182, np.int64(10): 42, np.int64(11): 158}\n",
      "Fold 1 라벨 분포: {np.int64(0): 156, np.int64(1): 107, np.int64(2): 242, np.int64(3): 711, np.int64(4): 25, np.int64(5): 248, np.int64(6): 190, np.int64(7): 17, np.int64(8): 268, np.int64(9): 182, np.int64(10): 42, np.int64(11): 158}\n",
      "Fold 2 라벨 분포: {np.int64(0): 156, np.int64(1): 107, np.int64(2): 241, np.int64(3): 712, np.int64(4): 25, np.int64(5): 248, np.int64(6): 190, np.int64(7): 16, np.int64(8): 268, np.int64(9): 183, np.int64(10): 42, np.int64(11): 158}\n",
      "Fold 3 라벨 분포: {np.int64(0): 156, np.int64(1): 106, np.int64(2): 242, np.int64(3): 712, np.int64(4): 25, np.int64(5): 248, np.int64(6): 190, np.int64(7): 16, np.int64(8): 268, np.int64(9): 182, np.int64(10): 43, np.int64(11): 158}\n",
      "Fold 4 라벨 분포: {np.int64(0): 156, np.int64(1): 106, np.int64(2): 242, np.int64(3): 712, np.int64(4): 24, np.int64(5): 248, np.int64(6): 191, np.int64(7): 16, np.int64(8): 268, np.int64(9): 182, np.int64(10): 42, np.int64(11): 159}\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "for f in folds:\n",
    "    counter = collections.Counter(f['y_test'])\n",
    "    print(f\"Fold {f['fold']} 라벨 분포: {dict(counter)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing (image enhancement)\n",
    "\n",
    "# Point Processing\n",
    "def contrast_stretch(image):\n",
    "    # 2% ~ 98% 범위로 contrast stretching\n",
    "    p2, p98 = np.percentile(image, (2, 98))\n",
    "    return exposure.rescale_intensity(image, in_range=(p2, p98))\n",
    "\n",
    "# Gray scale / HSI 변환\n",
    "def to_grayscale(image):\n",
    "    if len(image.shape) == 3:\n",
    "        return color.rgb2gray(image)\n",
    "    else:\n",
    "        print(\"hsi 변형 불가능\")\n",
    "        return image\n",
    "\n",
    "def to_hsi(image):\n",
    "    hsv = color.rgb2hsv(image)\n",
    "    return hsv[:, :, 0], hsv[:, :, 1], hsv[:, :, 2]  # hue, sat, intensity\n",
    "\n",
    "# Histogram Equalization (area processing)\n",
    "def histogram_equalization(image):\n",
    "    return exposure.equalize_hist(image)\n",
    "\n",
    "# Noise Filtering \n",
    "def remove_noise(image):\n",
    "    image = gaussian(image, sigma=1)\n",
    "    return denoise_bilateral(image, sigma_color=0.05, sigma_spatial=15, channel_axis=None)\n",
    "\n",
    "# Morphological Operators \n",
    "def morphological_close(image_binary, selem_size=3):\n",
    "    selem = disk(selem_size)\n",
    "    return morphology.closing(image_binary, selem)\n",
    "\n",
    "def morphological_open(image_binary, selem_size=3):\n",
    "    selem = disk(selem_size)\n",
    "    return morphology.opening(image_binary, selem)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edge Feature\n",
    "\n",
    "# Edge Detection \n",
    "def sobel_detection(image_gray):\n",
    "    return sobel(image_gray)\n",
    "\n",
    "def edge_detection(image_gray, low_threshold=50, high_threshold=150, aperture_size=3):\n",
    "    return cv2.Canny(image_gray, low_threshold, high_threshold, apertureSize=aperture_size)\n",
    "\n",
    "# Sharpening: Unsharp Mask 대신 Canny 엣지로 마스크 생성 후 강조\n",
    "def sharpen_image(image_gray, low_threshold=50, high_threshold=150, amount=1.0):\n",
    "    # 1) Canny 엣지 맵\n",
    "    edges = cv2.Canny(image_gray, low_threshold, high_threshold)\n",
    "    # 2) 엣지를 mask로 사용해 원본에 더함\n",
    "    #    edges는 0/255 이므로 255로 나눈 뒤 float 연산\n",
    "    mask = (edges / 255.0).astype(np.float32)\n",
    "    sharpened = image_gray.astype(np.float32) + amount * (mask * 255.0)\n",
    "    # 3) uint8로 클리핑 후 반환\n",
    "    return np.clip(sharpened, 0, 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Color Feature\n",
    "\n",
    "def extract_color_features(image):\n",
    "    # RGB 히스토그램\n",
    "    hist_r = cv2.calcHist([image], [0], None, [32], [0, 256])\n",
    "    hist_g = cv2.calcHist([image], [1], None, [32], [0, 256])\n",
    "    hist_b = cv2.calcHist([image], [2], None, [32], [0, 256])\n",
    "    \n",
    "    # HSV 변환 및 히스토그램\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    hist_h = cv2.calcHist([hsv], [0], None, [32], [0, 180])\n",
    "    hist_s = cv2.calcHist([hsv], [1], None, [32], [0, 256])\n",
    "    hist_v = cv2.calcHist([hsv], [2], None, [32], [0, 256])\n",
    "    \n",
    "    # 정규화\n",
    "    features = np.concatenate([\n",
    "        hist_r.flatten(), hist_g.flatten(), hist_b.flatten(),\n",
    "        hist_h.flatten(), hist_s.flatten(), hist_v.flatten()\n",
    "    ])\n",
    "    return features / np.sum(features)  # 정규화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Texture Feature\n",
    "\n",
    "# LBP 함수\n",
    "def extract_lbp_features(image_gray, radius=1, method='uniform'):\n",
    "    n_points = 8 * radius\n",
    "    lbp = feature.local_binary_pattern(image_gray, n_points, radius, method)\n",
    "    n_bins = int(lbp.max() + 1)\n",
    "    hist, _ = np.histogram(lbp.ravel(), bins=n_bins, range=(0, n_bins), density=True)\n",
    "    return hist\n",
    "\n",
    "# Laws' Texture Energy 함수\n",
    "def extract_laws_energy_features(image_gray, window_size=15):\n",
    "    # 1D Laws kernels\n",
    "    L5 = np.array([1, 4, 6, 4, 1], dtype=np.float32)\n",
    "    E5 = np.array([-1, -2,  0,  2,  1], dtype=np.float32)\n",
    "    S5 = np.array([-1,  0,  2,  0, -1], dtype=np.float32)\n",
    "    W5 = np.array([-1,  2,  0, -2,  1], dtype=np.float32)\n",
    "    R5 = np.array([1, -4,  6, -4,  1], dtype=np.float32)\n",
    "    kernels = [L5, E5, S5, W5, R5]\n",
    "\n",
    "    energy_features = []\n",
    "    for k1 in kernels:\n",
    "        for k2 in kernels:\n",
    "            # build 2D Laws kernel\n",
    "            kernel = np.outer(k1, k2)\n",
    "            # convolve and take absolute value (energy)\n",
    "            filtered = ndimage.convolve(image_gray.astype(np.float32),\n",
    "                                        kernel, mode='reflect')\n",
    "            energy = np.abs(filtered)\n",
    "            # sum local energy with a box filter\n",
    "            summed = cv2.boxFilter(energy, ddepth=-1,\n",
    "                                   ksize=(window_size, window_size),\n",
    "                                   normalize=False)\n",
    "            # global average energy for this filter\n",
    "            energy_features.append(summed.mean())\n",
    "\n",
    "    return np.array(energy_features, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape Feature\n",
    "\n",
    "def extract_sift_descriptors(image):\n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(image, None)\n",
    "\n",
    "    return descriptors\n",
    "\n",
    "def extract_hog_descriptors(image):\n",
    "    features = hog(\n",
    "        image,\n",
    "        orientations=9,\n",
    "        pixels_per_cell=(8, 8),\n",
    "        cells_per_block=(2, 2),\n",
    "        block_norm='L2-Hys',\n",
    "        transform_sqrt=True,\n",
    "        feature_vector=True\n",
    "    )\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 함수\n",
    "def preprocess_image(img, sigma=1.0):\n",
    "    img = contrast_stretch(img)\n",
    "    img = to_grayscale(img)\n",
    "    img = histogram_equalization(img)\n",
    "    img = remove_noise(img)\n",
    "    img = edge_detection(img)\n",
    "    img = sharpen_image(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature 함수\n",
    "def extract_features(img):\n",
    "    \"\"\"\n",
    "    img: 2D np.uint8 grayscale image\n",
    "    returns: L2-normalized 1D feature vector combining LBP, HOG, SIFT, and Laws energy.\n",
    "    \"\"\"\n",
    "    # 1) 입력이 이미 그레이스케일이라 가정, uint8 보장\n",
    "    gray = img.astype(np.uint8)\n",
    "\n",
    "    # 2) 개별 피처 추출\n",
    "    lbp_vec  = extract_lbp_features(gray, radius=1, method='uniform')\n",
    "    hog_vec  = extract_hog_descriptors(gray)\n",
    "    desc     = extract_sift_descriptors(gray)  # 반드시 uint8\n",
    "    if desc is not None and len(desc) > 0:\n",
    "        sift_vec = desc.mean(axis=0).astype(np.float32)  # 128D\n",
    "    else:\n",
    "        sift_vec = np.zeros(128, dtype=np.float32)\n",
    "    laws_vec = extract_laws_energy_features(gray, window_size=15)\n",
    "\n",
    "    # 3) 그룹별 정규화\n",
    "    norm = np.linalg.norm(lbp_vec, ord=1)\n",
    "    if norm > 0: lbp_vec /= norm\n",
    "\n",
    "    norm = np.linalg.norm(hog_vec, ord=2)\n",
    "    if norm > 0: hog_vec /= norm\n",
    "\n",
    "    norm = np.linalg.norm(sift_vec, ord=2)\n",
    "    if norm > 0: sift_vec /= norm\n",
    "\n",
    "    norm = np.linalg.norm(laws_vec, ord=2)\n",
    "    if norm > 0: laws_vec /= norm\n",
    "\n",
    "    # 4) 최종 벡터 합치고 전체 L2 정규화\n",
    "    feat = np.concatenate([lbp_vec, hog_vec, sift_vec, laws_vec]).astype(np.float32)\n",
    "    norm = np.linalg.norm(feat, ord=2)\n",
    "    if norm > 0:\n",
    "        feat /= norm\n",
    "\n",
    "    return feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-means clustering\n",
    "def kmeans_clustering(features, n_clusters=10):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    cluster_labels = kmeans.fit_predict(features)\n",
    "    return kmeans, cluster_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier (knn)\n",
    "\n",
    "def chi2_distance(x, y):\n",
    "    \"\"\"\n",
    "    Chi-square distance for histogram features.\n",
    "    Returns 0.5 * sum((x - y)^2 / (x + y + eps)).\n",
    "    \"\"\"\n",
    "    eps = 1e-10\n",
    "    return 0.5 * np.sum((x - y) ** 2 / (x + y + eps))\n",
    "\n",
    "def train_knn_classifier(features, labels, n_neighbors=5, weights='distance', metric='chi2'):\n",
    "    if metric == 'chi2':\n",
    "        metric_fn = chi2_distance\n",
    "    else:\n",
    "        metric_fn = metric  # can be 'euclidean', 'cosine', or a callable\n",
    "\n",
    "    knn = KNeighborsClassifier(\n",
    "        n_neighbors=n_neighbors,\n",
    "        weights=weights,\n",
    "        metric=metric_fn\n",
    "    )\n",
    "    knn.fit(features, labels)\n",
    "    return knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "\n",
    "def train(images, labels, test_size=0.2, random_state=42, n_neighbors=5):\n",
    "    \"\"\"\n",
    "    images: list or array of raw BGR/gray numpy 이미지\n",
    "    labels: list or array of 대응하는 라벨\n",
    "    test_size: 테스트 셋 비율 (0~1)\n",
    "    random_state: 재현을 위한 시드\n",
    "    n_neighbors: KNN의 k 값\n",
    "    Returns:\n",
    "        knn      : 학습된 KNeighborsClassifier 모델\n",
    "        X_test   : 테스트용 feature 벡터 (np.ndarray)\n",
    "        y_test   : 테스트용 라벨 배열\n",
    "    \"\"\"\n",
    "    # 1) 피처 벡터 추출\n",
    "    X = [extract_features(preprocess_image(img)) for img in images]\n",
    "    y = np.array(labels)\n",
    "\n",
    "    # 2) 학습/테스트 분할 (레이블 비율 유지)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y,\n",
    "        test_size=test_size,\n",
    "        stratify=y,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    # 3) KNN 학습\n",
    "    knn = train_knn_classifier(np.array(X_train), y_train, n_neighbors=n_neighbors)\n",
    "    return knn, np.array(X_test), y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "def test(model, X_test, y_test):\n",
    "    \"\"\"\n",
    "    model: train()이 반환한 KNeighborsClassifier\n",
    "    X_test: train()이 반환한 테스트 feature 벡터\n",
    "    y_test: train()이 반환한 테스트 라벨\n",
    "    Prints:\n",
    "        - 전체 정확도\n",
    "        - 각 클래스별 리포트\n",
    "    Returns:\n",
    "        y_pred: 예측된 라벨 배열\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"[Test Accuracy] {acc:.4f}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return y_pred"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
